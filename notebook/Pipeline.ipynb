{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3204a5fb",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b88a2a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Imports\n",
    "import time\n",
    "from IPython.display import display, Javascript\n",
    "import itertools\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "# Data process\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "# Train\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Models\n",
    "import umap\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "#from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Install sqlite as a extension of duckdb\n",
    "#duckdb.install_extension('sqlite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42da78f0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1cecc9",
   "metadata": {},
   "source": [
    "#### Functions to correct errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22618056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to drop zeros\n",
    "def drop_zeros(df):\n",
    "    df = df.drop(df[df['x'] == 0].index)\n",
    "    df = df.drop(df[df['y'] == 0].index)\n",
    "    df = df.drop(df[df['z'] == 0].index)\n",
    "    return df\n",
    "\n",
    "\"\"\"\n",
    "# Function to remove outliers\n",
    "def remove_outliers(df):\n",
    "    df = df[(df['x'] < 30)]\n",
    "    df = df[(df['y'] < 30)]\n",
    "    df = df[(df['z'] < 7.5) & (df['z'] > 2)]\n",
    "    df = df[(df['table'] < 80) & (df['table'] > 40)]\n",
    "    df = df[(df['depth'] < 75) & (df['depth'] > 45)]\n",
    "    return df\n",
    "\"\"\"\n",
    "\n",
    "def remove_outliers(df):\n",
    "    if 'x' in df.columns:\n",
    "        df = df[df['x'] < 20]\n",
    "    if 'y' in df.columns:\n",
    "        df = df[df['y'] < 20]\n",
    "    if 'z' in df.columns:\n",
    "        df = df[(df['z'] < 7.5) & (df['z'] > 2)]\n",
    "    if 'table' in df.columns:\n",
    "        df = df[(df['table'] < 80) & (df['table'] > 20)]\n",
    "    if 'depth' in df.columns:\n",
    "        df = df[(df['depth'] < 75) & (df['depth'] > 45)]\n",
    "    return df\n",
    "\n",
    "# Function to remove duplicates\n",
    "def remove_duplicates(df):\n",
    "    df = df.drop_duplicates()\n",
    "    return df\n",
    "\n",
    "# Function to impute values:\n",
    "def imputation(df):\n",
    "    # Calculate the median of each column\n",
    "    median_x = df.loc[df['x'] != 0, 'x'].median()\n",
    "    median_y = df.loc[df['y'] != 0, 'y'].median()\n",
    "    median_z = df.loc[df['z'] != 0, 'z'].median()\n",
    "\n",
    "    # Replace values equal to 0 by the corresponding median.\n",
    "    df['x'] = df['x'].replace(0, median_x)\n",
    "    df['y'] = df['y'].replace(0, median_y)\n",
    "    df['z'] = df['z'].replace(0, median_z)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e52141",
   "metadata": {},
   "source": [
    "#### Functions to encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f46a8eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(df):\n",
    "    df_enc = df.copy()\n",
    "\n",
    "    # Obtain the dataframe encoded\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object':\n",
    "            enc_label = LabelEncoder()\n",
    "            df_enc[column] = enc_label.fit_transform(df[column])\n",
    "    return df_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40300a1b",
   "metadata": {},
   "source": [
    "#### Functions to features ingeniering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f4df4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_ing(df_features):\n",
    "    #print('Dataframe features: ',df_features.head())\n",
    "    # Test the depth calculate\n",
    "    df_features['depth_mm'] = (df_features['z']*2)/(df_features['x'] + df_features['y'])\n",
    "    # Obtain the average girdle diameter\n",
    "    df_features['avg_girdle'] = (df_features['z'])/(df_features['depth_mm'])\n",
    "    # Obtain table in mm\n",
    "    df_features['table_mm'] = (df_features['avg_girdle'])*(df_features['table'])/100\n",
    "    # Obtain table*depth\n",
    "    df_features['table_depth'] = (df_features['table'])/(df_features['depth'])\n",
    "    # Obtain x, y, z\n",
    "    df_features['xyz'] = (df_features['x'])*(df_features['y'])*(df_features['z'])\n",
    "    return df_features\n",
    "\n",
    "# Function to calculate log\n",
    "def calculate_log(df, name):\n",
    "    list_log= []\n",
    "    for i in df['carat']:\n",
    "        list_log.append(math.log(i))\n",
    "    \n",
    "    new_name = name + '_log'\n",
    "    df[new_name] = list_log\n",
    "    return df\n",
    "\n",
    "# Funtion to classify diamond shape\n",
    "def classify_shape(df):\n",
    "    shape = []\n",
    "    for i in df['table'].index:\n",
    "        if 54<df['table'][i]<57 and 61<df['depth'][i]<62.5:\n",
    "            shape.append('Round')\n",
    "        elif 52<df['table'][i]<60 and 60<df['depth'][i]<68:\n",
    "            shape.append('Oval')\n",
    "        elif 63<df['table'][i]<69 and 69<df['depth'][i]<76:\n",
    "            shape.append('Princess')\n",
    "        elif 58<df['table'][i]<63 and 58<df['depth'][i]<66:\n",
    "            shape.append('Cushion')\n",
    "        else:\n",
    "            shape.append('others')\n",
    "            \n",
    "    df['shape'] = shape\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ea1a37",
   "metadata": {},
   "source": [
    "#### Functions to remove uncorrelated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11385831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to delete features without correlation with price (train data)\n",
    "def delete_features_train(df):\n",
    "    # Calculate correlation matrix, round with two decimmals\n",
    "    corr_matrix = round(df.corr(numeric_only=True).abs(),2)\n",
    "    \n",
    "    # Plot the heatmap\n",
    "    #sns.set (rc = {'figure.figsize':(16, 6)})\n",
    "    #sns.heatmap(corr_matrix, center=0, cmap='BrBG', annot=True)\n",
    "\n",
    "    # Find features with correlation greater than 0.90\n",
    "    to_drop = corr_matrix.columns[corr_matrix['price'] <= 0.1]\n",
    "    #print(to_drop)\n",
    "\n",
    "    # Drop features\n",
    "    df_correct = df\n",
    "    df_correct.drop(to_drop, axis=1, inplace=True)\n",
    "    \n",
    "    return df_correct,to_drop\n",
    "\n",
    "# Function to delete features without correlation with price (test data)\n",
    "def delete_features_test(df, to_drop):\n",
    "    # Calculate correlation matrix, round with two decimmals\n",
    "    corr_matrix = round(df.corr(numeric_only=True).abs(),2)\n",
    "    \n",
    "    # Plot the heatmap\n",
    "    #sns.set (rc = {'figure.figsize':(16, 6)})\n",
    "    #sns.heatmap(corr_matrix, center=0, cmap='BrBG', annot=True)\n",
    "\n",
    "    # Drop features\n",
    "    df_correct = df\n",
    "    df_correct.drop(to_drop, axis=1, inplace=True)\n",
    "    \n",
    "    return df_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc942cf",
   "metadata": {},
   "source": [
    "#### Scaling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dcc0228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stardard_scale_test(df):\n",
    "    X = df.drop('price',axis = 1)\n",
    "    columns = X.columns\n",
    "    # Scaler\n",
    "    scaler = StandardScaler()\n",
    "    # Scale X\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d075d5",
   "metadata": {},
   "source": [
    "#### Pipeline function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e8c94dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIPELINE 1\n",
    "# Building the Pipelines\n",
    "\n",
    "#Linear Regression\n",
    "lr_pipeline = Pipeline([\n",
    "    ('scaler_1',StandardScaler()),\n",
    "    ('lr_classifier',LinearRegression())\n",
    "])\n",
    "# knn\n",
    "knn_pipline =Pipeline([\n",
    "    ('scaler_2' ,StandardScaler()),\n",
    "    ('knn_classifier',KNeighborsRegressor())\n",
    "])\n",
    "\n",
    "#XGB\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('scaler_3', StandardScaler()),\n",
    "    ('xgb_classifier', XGBRegressor())\n",
    "])\n",
    "\n",
    "\n",
    "#Decision Tree\n",
    "dt_pipeline = Pipeline([\n",
    "    ('scaler_4', StandardScaler()),\n",
    "    ('dt_classifier', DecisionTreeRegressor())\n",
    "])\n",
    "\n",
    "#Random Forest\n",
    "rf_pipeline = Pipeline([\n",
    "    ('scaler_5', StandardScaler()),\n",
    "    ('rf_classifier', RandomForestRegressor(random_state = 42,\n",
    "                                            n_jobs=-1))\n",
    "])\n",
    "\n",
    "#pipelines = [lr_pipeline,knn_pipline,dt_pipeline,rf_pipeline]   #,xgb_pipeline\n",
    "#models = ['Linear Regression', 'KNN', 'Decision Tree', 'Random Forest']   #, 'XGB'\n",
    "\n",
    "pipelines = [rf_pipeline, xgb_pipeline]\n",
    "models = ['Random Forest', 'XGB']\n",
    "\n",
    "\n",
    "# PIPELINE 2\n",
    "\n",
    "\n",
    "features_pipeline = ColumnTransformer([\n",
    "    ('Drop zeros', drop_zeros),\n",
    "    ('Remove outliers', remove_outliers),\n",
    "    ('Remove duplicates', remove_duplicates),\n",
    "    ('Feature ingeniering', feature_ing),])\n",
    "\n",
    "\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    ('Drop zeros', drop_zeros),\n",
    "    ('Remove outliers', remove_outliers),\n",
    "    ('Remove duplicates', remove_duplicates),\n",
    "    ('Feature ingeniering', feature_ing)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9962ad2",
   "metadata": {},
   "source": [
    "#### Automation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9120c388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def version1_without_scaler2(df, drop_zeros_var, imputation_var, remove_outliers_var, remove_duplicates_var,\n",
    "                             feature_ing_var, delete_features_var, encoder_var=1):\n",
    "    # Transformations\n",
    "    if drop_zeros_var == 1:\n",
    "        df = drop_zeros(df)   # Drop zeros\n",
    "        \n",
    "    if imputation_var ==1:\n",
    "        df = imputation(df)   # Imputation data\n",
    "        \n",
    "    if remove_outliers_var == 1:\n",
    "        df = remove_outliers(df)   # Remove outliers\n",
    "        \n",
    "    if remove_duplicates_var == 1:\n",
    "        df = remove_duplicates(df)   # Remove duplicates\n",
    "        \n",
    "    if encoder_var == 1:\n",
    "        df = encoder(df)   # Encoding\n",
    "        \n",
    "    if feature_ing_var == 1:\n",
    "        df = feature_ing(df)   # Feature ingeniering\n",
    "        \n",
    "    if delete_features_var == 1:\n",
    "        df, to_drop = delete_features_train(df)   # Drop features\n",
    "        #print(to_drop)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d80bc8d",
   "metadata": {},
   "source": [
    "#### Test different models automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b5a4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame()\n",
    "\n",
    "# Definir las columnas con los nombres deseados\n",
    "column_names = ['model', 'cv_score', 'prediction', 'drop_zeros_var', 'imputation_var', 'remove_outliers_var', \n",
    "                'remove_duplicates_var', 'encoder_var', 'feature_ing_var', 'delete_features_var', 'cut', 'color', 'clarity', \n",
    "                'city', 'carat', 'depth', 'table', 'x', 'y', 'z', 'depth_mm', 'avg_girdle', 'table_mm', 'table_depth', 'xyz']\n",
    "\n",
    "# Asignar las columnas al DataFrame\n",
    "result_df = result_df.reindex(columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41642ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def automate_features_choice(df, pipelines, models, result_df):\n",
    "    # Combinations\n",
    "    cut         = [1]\n",
    "    color       = [1]   # [0, 1]\n",
    "    clarity     = [1]\n",
    "    city        = [1]\n",
    "    carat       = [1]\n",
    "    depth       = [1]\n",
    "    table       = [1]\n",
    "    x           = [1]\n",
    "    y           = [1]\n",
    "    z           = [1]\n",
    "    depth_mm    = [0]\n",
    "    avg_girdle  = [0]\n",
    "    table_mm    = [0]\n",
    "    table_depth = [0]\n",
    "    xyz         = [0]\n",
    "    \n",
    "\n",
    "    # Generar todas las combinaciones posibles\n",
    "    combinations_features = itertools.product(cut, color, clarity, city, carat, depth, table, x, y, z, depth_mm, \n",
    "                                              avg_girdle, table_mm, table_depth, xyz)\n",
    "\n",
    "    #results = []\n",
    "    for comb in combinations_features:\n",
    "        #start_time = time.time()\n",
    "        \n",
    "        # Transform train data\n",
    "        df_transform = version1_without_scaler2(df,\n",
    "                                                drop_zeros_var=1,\n",
    "                                                imputation_var=0,\n",
    "                                                remove_outliers_var=1,\n",
    "                                                remove_duplicates_var=1,\n",
    "                                                feature_ing_var=1,\n",
    "                                                delete_features_var=0)\n",
    "        \n",
    "        # Obtain the features to train the model\n",
    "        cut, color, clarity, city, carat, depth, table, x, y, z, depth_mm,\\\n",
    "            avg_girdle, table_mm, table_depth, xyz = comb\n",
    "        \n",
    "        # List of all possible feature names\n",
    "        features_to_train = []\n",
    "        all_features = ['cut', 'color', 'clarity', 'city', 'carat', 'depth', 'table', 'x', 'y', 'z', 'depth_mm', \n",
    "                       'avg_girdle', 'table_mm', 'table_depth', 'xyz']\n",
    "        \n",
    "        # Iterate over features and add them to variables_with_value_1 if they have a value of 1\n",
    "        for feature in all_features:\n",
    "            if locals()[feature] == 1:\n",
    "                features_to_train.append(feature)\n",
    "\n",
    "        # splitting the dataset in test and train data . The prece will be the Target and the other columns the features\n",
    "        X = df_transform[features_to_train]\n",
    "        y = df_transform['price']\n",
    "        \n",
    "        # There are combinations in which all values are zero, in that case it isn't necessary train model\n",
    "        if df_transform.shape[1] >= 1:\n",
    "            # Split data\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=42)\n",
    "        \n",
    "            # Fit our models to the training data\n",
    "            for i in pipelines :\n",
    "                i.fit(X_train , y_train)\n",
    "\n",
    "            cv_results = []\n",
    "            for i, model in enumerate(pipelines):\n",
    "                # Cross validation\n",
    "                cv_score = cross_val_score(model, X_train, y_train, scoring=\"neg_root_mean_squared_error\", cv=5)\n",
    "                cv_results.append(cv_score)\n",
    "\n",
    "                # Test the result\n",
    "                pred = model.predict(X_test)\n",
    "\n",
    "                # Create list with featers used\n",
    "                features_value_list = list(comb)\n",
    "                \n",
    "                # Create list with process parameters\n",
    "                cv_score_mean = abs(np.mean(cv_results))\n",
    "                rmse = np.sqrt(metrics.mean_squared_error(y_test, pred))\n",
    "                process_list = [model, cv_score_mean, rmse, 1, 0, 1, 1, 1, 1, 0]\n",
    "                \n",
    "                # Create complete list\n",
    "                registros = process_list + features_value_list\n",
    "                \n",
    "                # Store the results in the results dataframe\n",
    "                result_df.loc[len(result_df.index)] = registros\n",
    "                print(model, rmse, comb)\n",
    "                \n",
    "            #end_time = time.time()\n",
    "            #print(\"Execution time: \", end_time - start_time)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd64814",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pipelines = [rf_pipeline]   #[lr_pipeline, knn_pipline, dt_pipeline, rf_pipeline, xgb_pipeline]\n",
    "models = ['Random Forest']   #['Linear Regression', 'KNN', 'Decision Tree', 'Random Forest', 'XGB']\n",
    "\n",
    "# Execute functions and sort data\n",
    "result_df = automate_features_choice(diamond_train_df, pipelines, models, result_df)\n",
    "#play_sound()\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "result_df_sorted = result_df.sort_values(by='prediction')\n",
    "result_df_sorted.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ead1ad2",
   "metadata": {},
   "source": [
    "#### Play sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4754ff32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_sound():\n",
    "    display(Javascript('new Audio(\"https://www.soundjay.com/button/beep-07.wav\").play()'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f79f26",
   "metadata": {},
   "source": [
    "## Extraction data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452341b0",
   "metadata": {},
   "source": [
    "#### Extraction data to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518366ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamond_train_df = pd.read_csv(\"../data/train/diamond_train_df_Nearest_all_features_3knn.csv\")\n",
    "diamond_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2224e0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamond_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c45558f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>price</th>\n",
       "      <th>city</th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Premium</td>\n",
       "      <td>J</td>\n",
       "      <td>VS2</td>\n",
       "      <td>4268</td>\n",
       "      <td>Dubai</td>\n",
       "      <td>1.21</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>6.83</td>\n",
       "      <td>6.79</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Very Good</td>\n",
       "      <td>H</td>\n",
       "      <td>VS2</td>\n",
       "      <td>505</td>\n",
       "      <td>Kimberly</td>\n",
       "      <td>0.32</td>\n",
       "      <td>63.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.38</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fair</td>\n",
       "      <td>G</td>\n",
       "      <td>VS1</td>\n",
       "      <td>2686</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>0.71</td>\n",
       "      <td>65.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5.62</td>\n",
       "      <td>5.53</td>\n",
       "      <td>3.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good</td>\n",
       "      <td>D</td>\n",
       "      <td>SI1</td>\n",
       "      <td>738</td>\n",
       "      <td>Kimberly</td>\n",
       "      <td>0.41</td>\n",
       "      <td>63.8</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.68</td>\n",
       "      <td>4.72</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>SI1</td>\n",
       "      <td>4882</td>\n",
       "      <td>Dubai</td>\n",
       "      <td>1.02</td>\n",
       "      <td>60.5</td>\n",
       "      <td>59.0</td>\n",
       "      <td>6.55</td>\n",
       "      <td>6.51</td>\n",
       "      <td>3.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cut color clarity  price       city  carat  depth  table     x     y  \\\n",
       "0    Premium     J     VS2   4268      Dubai   1.21   62.4   58.0  6.83  6.79   \n",
       "1  Very Good     H     VS2    505   Kimberly   0.32   63.0   57.0  4.35  4.38   \n",
       "2       Fair     G     VS1   2686  Las Vegas   0.71   65.5   55.0  5.62  5.53   \n",
       "3       Good     D     SI1    738   Kimberly   0.41   63.8   56.0  4.68  4.72   \n",
       "4      Ideal     G     SI1   4882      Dubai   1.02   60.5   59.0  6.55  6.51   \n",
       "\n",
       "      z  \n",
       "0  4.25  \n",
       "1  2.75  \n",
       "2  3.65  \n",
       "3  3.00  \n",
       "4  3.95  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a connection to a file called 'file.db'\n",
    "con = duckdb.connect(\"../data/train/diamonds_train.db\")\n",
    "\n",
    "# Query to extract data from database\n",
    "query_full = \"\"\"\n",
    "SELECT\n",
    "    --tra.index_id,\n",
    "    cut.cut,\n",
    "    col.color,\n",
    "    cla.clarity,\n",
    "    tra.price,\n",
    "    cit.city,\n",
    "    tra.carat,\n",
    "    dim.depth,\n",
    "    dim.table,\n",
    "    dim.x,\n",
    "    dim.y,\n",
    "    dim.z\n",
    "FROM diamonds_properties AS pro\n",
    "JOIN diamonds_cut AS cut ON pro.cut_id = cut.cut_id\n",
    "JOIN diamonds_color AS col ON pro.color_id = col.color_id\n",
    "JOIN diamonds_clarity AS cla ON pro.clarity_id = cla.clarity_id\n",
    "JOIN diamonds_transactional as tra ON pro.index_id = tra.index_id\n",
    "JOIN diamonds_city AS cit ON tra.city_id = cit.city_id\n",
    "JOIN diamonds_dimensions AS dim ON pro.index_id = dim.index_id\n",
    "\"\"\"\n",
    "\n",
    "diamond_train_df = con.execute(query_full).df()\n",
    "diamond_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17b694b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>F</td>\n",
       "      <td>SI1</td>\n",
       "      <td>62.7</td>\n",
       "      <td>60.0</td>\n",
       "      <td>5.82</td>\n",
       "      <td>5.89</td>\n",
       "      <td>3.67</td>\n",
       "      <td>Amsterdam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.20</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>J</td>\n",
       "      <td>VS1</td>\n",
       "      <td>61.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>6.81</td>\n",
       "      <td>6.89</td>\n",
       "      <td>4.18</td>\n",
       "      <td>Surat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.57</td>\n",
       "      <td>Premium</td>\n",
       "      <td>H</td>\n",
       "      <td>SI1</td>\n",
       "      <td>62.2</td>\n",
       "      <td>61.0</td>\n",
       "      <td>7.38</td>\n",
       "      <td>7.32</td>\n",
       "      <td>4.57</td>\n",
       "      <td>Kimberly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.90</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>F</td>\n",
       "      <td>SI1</td>\n",
       "      <td>63.8</td>\n",
       "      <td>54.0</td>\n",
       "      <td>6.09</td>\n",
       "      <td>6.13</td>\n",
       "      <td>3.90</td>\n",
       "      <td>Kimberly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.50</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>F</td>\n",
       "      <td>VS1</td>\n",
       "      <td>62.9</td>\n",
       "      <td>58.0</td>\n",
       "      <td>5.05</td>\n",
       "      <td>5.09</td>\n",
       "      <td>3.19</td>\n",
       "      <td>Amsterdam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  carat        cut color clarity  depth  table     x     y     z  \\\n",
       "0   0   0.79  Very Good     F     SI1   62.7   60.0  5.82  5.89  3.67   \n",
       "1   1   1.20      Ideal     J     VS1   61.0   57.0  6.81  6.89  4.18   \n",
       "2   2   1.57    Premium     H     SI1   62.2   61.0  7.38  7.32  4.57   \n",
       "3   3   0.90  Very Good     F     SI1   63.8   54.0  6.09  6.13  3.90   \n",
       "4   4   0.50  Very Good     F     VS1   62.9   58.0  5.05  5.09  3.19   \n",
       "\n",
       "        city  \n",
       "0  Amsterdam  \n",
       "1      Surat  \n",
       "2   Kimberly  \n",
       "3   Kimberly  \n",
       "4  Amsterdam  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamond_test_df = pd.read_csv(\"../data/test/diamonds_test.csv\")\n",
    "diamond_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4f49e2",
   "metadata": {},
   "source": [
    "#### Extract the dataframe with the parameters of all tested models and configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f887ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>cv_score</th>\n",
       "      <th>rmse</th>\n",
       "      <th>Submission</th>\n",
       "      <th>Features</th>\n",
       "      <th>Transformations</th>\n",
       "      <th>Estimators</th>\n",
       "      <th>Hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Voting model</td>\n",
       "      <td>534.5</td>\n",
       "      <td>529.8</td>\n",
       "      <td>538</td>\n",
       "      <td>['cut', 'color', 'clarity', 'city', 'carat', '...</td>\n",
       "      <td>['encoding', 'drop_zeros', 'remove_outliers', ...</td>\n",
       "      <td>['lgbm', 'xgb', 'extrees', 'rf']</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>563.6</td>\n",
       "      <td>541.8</td>\n",
       "      <td>597</td>\n",
       "      <td>['cut', 'color', 'clarity', 'city', 'depth', '...</td>\n",
       "      <td>['encoding', 'drop_zeros', 'remove_outliers', ...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'criteri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>563.1</td>\n",
       "      <td>541.9</td>\n",
       "      <td>597</td>\n",
       "      <td>['cut', 'color', 'clarity', 'city', 'depth', '...</td>\n",
       "      <td>['encoding', 'drop_zeros', 'remove_outliers', ...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'criteri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>568.2</td>\n",
       "      <td>545.7</td>\n",
       "      <td>0</td>\n",
       "      <td>['cut', 'color', 'clarity', 'city', 'depth', '...</td>\n",
       "      <td>['encoding', 'drop_zeros', 'remove_outliers', ...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'criteri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF</td>\n",
       "      <td>578.5</td>\n",
       "      <td>552.8</td>\n",
       "      <td>552</td>\n",
       "      <td>['cut', 'color', 'clarity', 'carat_log', 'dept...</td>\n",
       "      <td>['encoding', 'imputation', 'remove_outliers', ...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'criteri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model  cv_score   rmse  Submission  \\\n",
       "0  Voting model     534.5  529.8         538   \n",
       "1            RF     563.6  541.8         597   \n",
       "2            RF     563.1  541.9         597   \n",
       "3            RF     568.2  545.7           0   \n",
       "4            RF     578.5  552.8         552   \n",
       "\n",
       "                                            Features  \\\n",
       "0  ['cut', 'color', 'clarity', 'city', 'carat', '...   \n",
       "1  ['cut', 'color', 'clarity', 'city', 'depth', '...   \n",
       "2  ['cut', 'color', 'clarity', 'city', 'depth', '...   \n",
       "3  ['cut', 'color', 'clarity', 'city', 'depth', '...   \n",
       "4  ['cut', 'color', 'clarity', 'carat_log', 'dept...   \n",
       "\n",
       "                                     Transformations  \\\n",
       "0  ['encoding', 'drop_zeros', 'remove_outliers', ...   \n",
       "1  ['encoding', 'drop_zeros', 'remove_outliers', ...   \n",
       "2  ['encoding', 'drop_zeros', 'remove_outliers', ...   \n",
       "3  ['encoding', 'drop_zeros', 'remove_outliers', ...   \n",
       "4  ['encoding', 'imputation', 'remove_outliers', ...   \n",
       "\n",
       "                         Estimators  \\\n",
       "0  ['lgbm', 'xgb', 'extrees', 'rf']   \n",
       "1                            [None]   \n",
       "2                            [None]   \n",
       "3                            [None]   \n",
       "4                            [None]   \n",
       "\n",
       "                                     Hyperparameters  \n",
       "0                                                 {}  \n",
       "1  {'bootstrap': True, 'ccp_alpha': 0.0, 'criteri...  \n",
       "2  {'bootstrap': True, 'ccp_alpha': 0.0, 'criteri...  \n",
       "3  {'bootstrap': True, 'ccp_alpha': 0.0, 'criteri...  \n",
       "4  {'bootstrap': True, 'ccp_alpha': 0.0, 'criteri...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_df = pd.read_csv('./parameters_training/best_parameters_prediction_models.csv')\n",
    "parameters_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5696a87c",
   "metadata": {},
   "source": [
    "## Train and test models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fee8d4",
   "metadata": {},
   "source": [
    "#### Non-linear relation between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070d948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe the non-linear relation between features\n",
    "X = transformed_df.copy()\n",
    "y = X.pop(\"price\")\n",
    "\n",
    "def make_mi_scores(X, y):\n",
    "    mi_scores = mutual_info_regression(X, y)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index = X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "\n",
    "mi_scores = make_mi_scores(X, y)\n",
    "mi_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a9f951",
   "metadata": {},
   "source": [
    "### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "381f2dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>city</th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>shape</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1.21</td>\n",
       "      <td>62.4</td>\n",
       "      <td>1</td>\n",
       "      <td>6.83</td>\n",
       "      <td>6.79</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.32</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.38</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.71</td>\n",
       "      <td>65.5</td>\n",
       "      <td>1</td>\n",
       "      <td>5.62</td>\n",
       "      <td>5.53</td>\n",
       "      <td>3.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.41</td>\n",
       "      <td>63.8</td>\n",
       "      <td>1</td>\n",
       "      <td>4.68</td>\n",
       "      <td>4.72</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.02</td>\n",
       "      <td>60.5</td>\n",
       "      <td>1</td>\n",
       "      <td>6.55</td>\n",
       "      <td>6.51</td>\n",
       "      <td>3.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cut  color  clarity  city  carat  depth  shape     x     y     z\n",
       "0    3      6        5     2   1.21   62.4      1  6.83  6.79  4.25\n",
       "1    4      4        5     3   0.32   63.0      1  4.35  4.38  2.75\n",
       "2    0      3        4     4   0.71   65.5      1  5.62  5.53  3.65\n",
       "3    1      0        2     3   0.41   63.8      1  4.68  4.72  3.00\n",
       "4    2      3        2     2   1.02   60.5      1  6.55  6.51  3.95"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All features\n",
    "# selection_features = ['cut', 'color', 'clarity', 'city', 'carat', 'depth', 'shape', \n",
    "#                       'x_log', 'y_log', 'z_log', 'carat_log', 'ratio_length_width', 'ratio_length_width_depth', \n",
    "#                       'volume', 'density', 'price']\n",
    "\n",
    "# Transform\n",
    "def transformation_data(df, type_data):\n",
    "    trans_df = classify_shape(df)\n",
    "    trans_df = encoder(trans_df)\n",
    "    #trans_df = imputation(trans_df)\n",
    "\n",
    "    if type_data == 'train_data':\n",
    "        #trans_df = drop_zeros(trans_df)\n",
    "        #trans_df = remove_outliers(trans_df)\n",
    "        #trans_df = remove_duplicates(trans_df)\n",
    "        selection_features = ['cut', 'color', 'clarity', 'city', 'carat', 'depth', 'shape', 'x', 'y', 'z', 'price']\n",
    "        #selection_features = ['cut', 'color', 'clarity', 'city', 'carat', 'depth', 'table','x', 'y', 'z', 'price']\n",
    "    \n",
    "    if type_data == 'test_data':\n",
    "        selection_features = ['cut', 'color', 'clarity', 'city', 'carat', 'depth', 'shape', 'x', 'y', 'z']     \n",
    "        #selection_features = ['cut', 'color', 'clarity', 'city', 'carat', 'depth', 'table', 'x', 'y', 'z']\n",
    "        \n",
    "    trans_df = feature_ing(trans_df)\n",
    "    \n",
    "    # Calculate others features\n",
    "    trans_df = calculate_log(trans_df, 'carat')\n",
    "    trans_df = calculate_log(trans_df, 'x')\n",
    "    trans_df = calculate_log(trans_df, 'y')\n",
    "    trans_df = calculate_log(trans_df, 'z')\n",
    "    trans_df['ratio_length_width'] = trans_df['x']/trans_df['y']\n",
    "    trans_df['ratio_length_width_depth'] = trans_df['x']/trans_df['y']/trans_df['z']\n",
    "    trans_df['volume'] = trans_df['x']*trans_df['y']*trans_df['z']\n",
    "    trans_df['density'] = trans_df['carat']/trans_df['volume']\n",
    "    \n",
    "    # Only used selection features\n",
    "    trans_df_2 = trans_df[selection_features]\n",
    "    trans_df_2.head()\n",
    "    \n",
    "    return trans_df_2, selection_features\n",
    "\n",
    "#Transformations:\n",
    "transformations = ['encoding', 'drop_zeros'] #, 'remove_outliers', 'remove_duplicates']\n",
    "\n",
    "transformed_df, selection_features = transformation_data(diamond_train_df, 'train_data')\n",
    "X = transformed_df.drop('price',axis = 1)\n",
    "y = transformed_df['price']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7379aa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.to_csv('../data/processed/x_data.csv', index=False)\n",
    "#y.to_csv('../data/processed/y_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9b0e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain data for training and testing. It is necessary to modify the pipeline to check this because the input to the \n",
    "# models is the complete dataset, in order to upload it to kaggle.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6481af",
   "metadata": {},
   "source": [
    "### Fine-Tuning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293f81cf",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd17ec28",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_xgb = {'n_estimators': [950],  # Number of trees in the forest.\n",
    "                  'max_depth': [5],  # Maximum depth of the trees.\n",
    "                  'subsample': [1],\n",
    "                  'colsample_bytree': [0.8],\n",
    "                  'lambda': [0.7],\n",
    "                  'gamma': [0.05],\n",
    "                  'learning_rate': [0.035]\n",
    "                 }\n",
    "\n",
    "xgb_reg = XGBRegressor(random_state=0)\n",
    "\n",
    "xgb_grid_search = GridSearchCV(xgb_reg, param_grid_xgb, cv=5, scoring='neg_root_mean_squared_error', return_train_score=True, verbose=1, n_jobs=-1)\n",
    "\n",
    "xgb_grid_search.fit(X, y)\n",
    "\n",
    "print('\\n')\n",
    "print('Best hyperparameters: ', xgb_grid_search.best_params_, '\\n')\n",
    "print('Best score: ', xgb_grid_search.best_score_, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa78cc7",
   "metadata": {},
   "source": [
    "#### LGBM Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dd6477",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lgbm = {'num_leaves': [30], \n",
    "                   'learning_rate': [0.02] ,\n",
    "                   'n_estimators': [1300],\n",
    "                   'max_depth': [-1]\n",
    "                  }\n",
    "\n",
    "lgbm_reg = LGBMRegressor(random_state=0)\n",
    "\n",
    "lgbm_grid_search = GridSearchCV(param_grid_lgbm, param_grid, cv=5, scoring='neg_root_mean_squared_error', return_train_score=True, verbose=1, n_jobs=-1)\n",
    "\n",
    "lgbm_grid_search.fit(X, y)\n",
    "\n",
    "print('\\n')\n",
    "print('Best hyperparameters: ', lgbm_grid_search.best_params_, '\\n')\n",
    "print('Best score: ', lgbm_grid_search.best_score_, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1574afce",
   "metadata": {},
   "source": [
    "#### ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4545031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [70, 100, 150], \n",
    "              'max_depth': [None],\n",
    "              'criterion': ['squared_error'],\n",
    "              'max_features': ['sqrt'],\n",
    "              'min_samples_leaf': [1, 2],\n",
    "              'min_samples_split': [3, 4]\n",
    "             }\n",
    "\n",
    "extrees_reg = ExtraTreesRegressor(random_state=0)\n",
    "\n",
    "extrees_grid_search = GridSearchCV(extrees_reg, param_grid, cv=5, scoring='neg_root_mean_squared_error', verbose=1, n_jobs=-1)\n",
    "\n",
    "extrees_grid_search.fit(X, y)\n",
    "\n",
    "print('\\n')\n",
    "print('Best hyperparameters: ', extrees_grid_search.best_params_, '\\n')\n",
    "print('Best score: ', extrees_grid_search.best_score_, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127354a9",
   "metadata": {},
   "source": [
    "#### RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166fde5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid_rf = {'n_estimators': [1400],  # Number of trees in the forest.\n",
    "                 'max_depth': [None],  # Maximum depth of the trees.\n",
    "                 'min_samples_split': [7],  # Minimum number of samples required to split an internal node.\n",
    "                 'min_samples_leaf': [1],  # Minimum number of samples required to be at a leaf node.\n",
    "                 'max_features': [None]  # Number of features to consider when looking for the best split.\n",
    "                }\n",
    "\n",
    "rf_reg = RandomForestRegressor(random_state=0)\n",
    "\n",
    "rf_grid_search = GridSearchCV(rf_reg, param_grid_rf, cv=5, scoring='neg_root_mean_squared_error', verbose=1, n_jobs=-1)\n",
    "\n",
    "rf_grid_search.fit(X, y)\n",
    "\n",
    "print('\\n')\n",
    "print('Best hyperparameters: ', rf_grid_search.best_params_, '\\n')\n",
    "print('Best score: ', rf_grid_search.best_score_, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcef0d87",
   "metadata": {},
   "source": [
    "#### MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faf34d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Define the model\n",
    "mlp = MLPRegressor(max_iter=100)\n",
    "\n",
    "# Set up the parameter grid\n",
    "param_grid_mlp = {'hidden_layer_sizes': [(50,100,50)],\n",
    "                  'activation': ['relu'],\n",
    "                  'solver': ['adam'],\n",
    "                  'alpha': [0.05],\n",
    "                 }\n",
    "\n",
    "# Instantiate GridSearchCV\n",
    "mlp_grid_search = GridSearchCV(mlp, param_grid_mlp, cv=5)\n",
    "\n",
    "# Fit the GridSearchCV object\n",
    "mlp_grid_search.fit(X, y)\n",
    "\n",
    "# Access the results\n",
    "print('\\n')\n",
    "print('Best hyperparameters: ', mlp_grid_search.best_params_, '\\n')\n",
    "print('Best score: ', mlp_grid_search.best_score_, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43d7b4f",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f93c4b",
   "metadata": {},
   "source": [
    "#### Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31027b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_xgb = {'n_estimators': 950,  # Number of trees in the forest.\n",
    "                  'max_depth': 5,  # Maximum depth of the trees.\n",
    "                  'subsample': 1,\n",
    "                  'colsample_bytree': 0.8,\n",
    "                  'lambda': 0.7,\n",
    "                  'gamma': 0.05,\n",
    "                  'learning_rate': 0.035\n",
    "                 }\n",
    "param_grid_lgbm = {'num_leaves': 30, \n",
    "                   'learning_rate': 0.02 ,\n",
    "                   'n_estimators': 1300,\n",
    "                   'max_depth': -1\n",
    "                  }\n",
    "param_grid_rf = {'n_estimators': 1400,  # Number of trees in the forest.\n",
    "                 'max_depth': None,  # Maximum depth of the trees.\n",
    "                 'min_samples_split': 7,  # Minimum number of samples required to split an internal node.\n",
    "                 'min_samples_leaf': 1,  # Minimum number of samples required to be at a leaf node.\n",
    "                 'max_features': None  # Number of features to consider when looking for the best split.\n",
    "                }\n",
    "param_grid_mlp = {'hidden_layer_sizes': (50,100,50),\n",
    "                  'activation': 'relu',\n",
    "                  'solver': 'adam',\n",
    "                  'alpha': 0.05,\n",
    "                 }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139f7ae8",
   "metadata": {},
   "source": [
    "#### Stacking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4477fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb_model = XGBRegressor(**param_grid_xgb)\n",
    "lgb_model = LGBMRegressor(**param_grid_lgbm)\n",
    "rf_model = RandomForestRegressor(**param_grid_rf)\n",
    "mlp_model = MLPRegressor(**param_grid_mlp)\n",
    "\n",
    "estimators = [('xgb1', xgb_model),\n",
    "              ('lgbm1', lgb_model),\n",
    "              ('rf', rf_model),\n",
    "              ('mlp', mlp_model)]\n",
    "              #('extrees', extrees_model),]\n",
    "\n",
    "# Train the model\n",
    "stack_model = StackingRegressor(estimators=estimators, cv=5, n_jobs=-1, verbose=True, passthrough=True)   #cv=None\n",
    "\n",
    "# Execute cross validation\n",
    "cv_results = []\n",
    "cv_score = cross_val_score(stack_model, X, y, scoring=\"neg_root_mean_squared_error\", cv=5)\n",
    "cv_results.append(cv_score)\n",
    "cv_score_mean = abs(np.mean(cv_results))\n",
    "\n",
    "# Fit the model\n",
    "stack_model.fit(X,y)\n",
    "\n",
    "# Print hyperparameters and cv_score\n",
    "hyperparameters = stack_model.get_params()\n",
    "cv_score_mean = abs(np.mean(cv_results))\n",
    "print('Hyperparameters: ', hyperparameters, ' | cv_score_mean:', cv_score_mean)\n",
    "\n",
    "# Save the parameters of the training performed and the score in the dataframe to keep track of all tests performed \n",
    "registers = [model_type, cv_score_mean, rmse, 0, selection_features, transformations, estimators, hyperparameters]\n",
    "parameters_df.loc[len(parameters_df.index)] = registers\n",
    "parameters_df.to_csv('./parameters_training/best_parameters_prediction_models.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0ff77a",
   "metadata": {},
   "source": [
    "### Transform test data and obtain the prediction to upload in kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77f287de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the prediction data\n",
    "X_test_all, selection_features2 = transformation_data(diamond_test_df, 'test_data')\n",
    "X_test_all.shape\n",
    "X_test_all.to_csv('../data/processed/x_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5a2429e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 562 ms\n",
      "Wall time: 87.1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13485"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Predict\n",
    "y_pred_all = model_all.predict(X_test_all)\n",
    "len(y_pred_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b75852ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and store the dataframe to upload to kaggle\n",
    "y_pred_df = pd.DataFrame(y_pred_all)\n",
    "y_pred_df.reset_index(inplace=True)\n",
    "y_pred_df.columns = ['id', 'price']\n",
    "y_pred_df.to_csv('../data/submisions/XGB_all_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m3_env",
   "language": "python",
   "name": "m3_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
