{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bdd14b3",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2876b7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Imports\n",
    "import time\n",
    "from IPython.display import display, Javascript\n",
    "import itertools\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "# Data process\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Train\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Models\n",
    "import umap\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Install sqlite as a extension of duckdb\n",
    "#duckdb.install_extension('sqlite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a290877",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfd9e3c",
   "metadata": {},
   "source": [
    "### Functions to correct errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43f95e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to drop zeros\n",
    "def drop_zeros(df):\n",
    "    df = df.drop(df[df['x'] == 0].index)\n",
    "    df = df.drop(df[df['y'] == 0].index)\n",
    "    df = df.drop(df[df['z'] == 0].index)\n",
    "    return df\n",
    "\n",
    "\"\"\"\n",
    "# Function to remove outliers\n",
    "def remove_outliers(df):\n",
    "    df = df[(df['x'] < 30)]\n",
    "    df = df[(df['y'] < 30)]\n",
    "    df = df[(df['z'] < 7.5) & (df['z'] > 2)]\n",
    "    df = df[(df['table'] < 80) & (df['table'] > 40)]\n",
    "    df = df[(df['depth'] < 75) & (df['depth'] > 45)]\n",
    "    return df\n",
    "\"\"\"\n",
    "\n",
    "def remove_outliers(df):\n",
    "    if 'x' in df.columns:\n",
    "        df = df[df['x'] < 20]\n",
    "    if 'y' in df.columns:\n",
    "        df = df[df['y'] < 20]\n",
    "    if 'z' in df.columns:\n",
    "        df = df[(df['z'] < 7.5) & (df['z'] > 2)]\n",
    "    if 'table' in df.columns:\n",
    "        df = df[(df['table'] < 80) & (df['table'] > 40)]\n",
    "    if 'depth' in df.columns:\n",
    "        df = df[(df['depth'] < 75) & (df['depth'] > 45)]\n",
    "    return df\n",
    "\n",
    "# Function to remove duplicates\n",
    "def remove_duplicates(df):\n",
    "    df = df.drop_duplicates()\n",
    "    return df\n",
    "\n",
    "# Function to impute values:\n",
    "def imputation(df):\n",
    "    # Calculate the median of each column\n",
    "    median_x = df.loc[df['x'] != 0, 'x'].median()\n",
    "    median_y = df.loc[df['y'] != 0, 'y'].median()\n",
    "    median_z = df.loc[df['z'] != 0, 'z'].median()\n",
    "\n",
    "    # Replace values equal to 0 by the corresponding median.\n",
    "    df['x'] = df['x'].replace(0, median_x)\n",
    "    df['y'] = df['y'].replace(0, median_y)\n",
    "    df['z'] = df['z'].replace(0, median_z)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1043d0",
   "metadata": {},
   "source": [
    "### Functions to encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc677289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(df):\n",
    "    df_enc = df.copy()\n",
    "\n",
    "    # Obtain the dataframe encoded\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object':\n",
    "            enc_label = LabelEncoder()\n",
    "            df_enc[column] = enc_label.fit_transform(df[column])\n",
    "    return df_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8523daa6",
   "metadata": {},
   "source": [
    "### Functions to features ingeniering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3e924f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_ing(df_features):\n",
    "    #print('Dataframe features: ',df_features.head())\n",
    "    # Test the depth calculate\n",
    "    df_features['depth_mm'] = (df_features['z']*2)/(df_features['x'] + df_features['y'])\n",
    "    # Obtain the average girdle diameter\n",
    "    df_features['avg_girdle'] = (df_features['z'])/(df_features['depth_mm'])\n",
    "    # Obtain table in mm\n",
    "    df_features['table_mm'] = (df_features['avg_girdle'])*(df_features['table'])/100\n",
    "    # Obtain table*depth\n",
    "    df_features['table_depth'] = (df_features['table'])/(df_features['depth'])\n",
    "    # Obtain x, y, z\n",
    "    df_features['xyz'] = (df_features['x'])*(df_features['y'])*(df_features['z'])\n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ad790a",
   "metadata": {},
   "source": [
    "### Functions to remove uncorrelated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cebbc4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to delete features without correlation with price (train data)\n",
    "def delete_features_train(df):\n",
    "    # Calculate correlation matrix, round with two decimmals\n",
    "    corr_matrix = round(df.corr(numeric_only=True).abs(),2)\n",
    "    \n",
    "    # Plot the heatmap\n",
    "    #sns.set (rc = {'figure.figsize':(16, 6)})\n",
    "    #sns.heatmap(corr_matrix, center=0, cmap='BrBG', annot=True)\n",
    "\n",
    "    # Find features with correlation greater than 0.90\n",
    "    to_drop = corr_matrix.columns[corr_matrix['price'] <= 0.1]\n",
    "    #print(to_drop)\n",
    "\n",
    "    # Drop features\n",
    "    df_correct = df\n",
    "    df_correct.drop(to_drop, axis=1, inplace=True)\n",
    "    \n",
    "    return df_correct,to_drop\n",
    "\n",
    "# Function to delete features without correlation with price (test data)\n",
    "def delete_features_test(df, to_drop):\n",
    "    # Calculate correlation matrix, round with two decimmals\n",
    "    corr_matrix = round(df.corr(numeric_only=True).abs(),2)\n",
    "    \n",
    "    # Plot the heatmap\n",
    "    #sns.set (rc = {'figure.figsize':(16, 6)})\n",
    "    #sns.heatmap(corr_matrix, center=0, cmap='BrBG', annot=True)\n",
    "\n",
    "    # Drop features\n",
    "    df_correct = df\n",
    "    df_correct.drop(to_drop, axis=1, inplace=True)\n",
    "    \n",
    "    return df_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee323e7c",
   "metadata": {},
   "source": [
    "### Scaling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be227046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stardard_scale_test(df):\n",
    "    X = df.drop('price',axis = 1)\n",
    "    columns = X.columns\n",
    "    # Scaler\n",
    "    scaler = StandardScaler()\n",
    "    # Scale X\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c71a8ce",
   "metadata": {},
   "source": [
    "### Pipeline function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbc88565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Pipelines\n",
    "\n",
    "#Linear Regression\n",
    "lr_pipeline = Pipeline([\n",
    "    ('scaler_1',StandardScaler()),\n",
    "    ('lr_classifier',LinearRegression())\n",
    "])\n",
    "# knn\n",
    "knn_pipline =Pipeline([\n",
    "    ('scaler_2' ,StandardScaler()),\n",
    "    ('knn_classifier',KNeighborsRegressor())\n",
    "])\n",
    "\n",
    "#XGB\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('scaler_3', StandardScaler()),\n",
    "    ('xgb_classifier', XGBRegressor())\n",
    "])\n",
    "\n",
    "\n",
    "#Decision Tree\n",
    "dt_pipeline = Pipeline([\n",
    "    ('scaler_4', StandardScaler()),\n",
    "    ('dt_classifier', DecisionTreeRegressor())\n",
    "])\n",
    "\n",
    "#Random Forest\n",
    "rf_pipeline = Pipeline([\n",
    "    ('scaler_5', StandardScaler()),\n",
    "    ('rf_classifier', RandomForestRegressor(random_state = 42,\n",
    "                                            n_jobs=-1))\n",
    "])\n",
    "\n",
    "#pipelines = [lr_pipeline,knn_pipline,dt_pipeline,rf_pipeline]   #,xgb_pipeline\n",
    "#models = ['Linear Regression', 'KNN', 'Decision Tree', 'Random Forest']   #, 'XGB'\n",
    "\n",
    "pipelines = [rf_pipeline, xgb_pipeline]\n",
    "models = ['Random Forest', 'XGB']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9782bb32",
   "metadata": {},
   "source": [
    "### Automation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "141059cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def version1_without_scaler2(df, drop_zeros_var, imputation_var, remove_outliers_var, remove_duplicates_var,\n",
    "                             feature_ing_var, delete_features_var, encoder_var=1):\n",
    "    # Transformations\n",
    "    if drop_zeros_var == 1:\n",
    "        df = drop_zeros(df)   # Drop zeros\n",
    "        \n",
    "    if imputation_var ==1:\n",
    "        df = imputation(df)   # Imputation data\n",
    "        \n",
    "    if remove_outliers_var == 1:\n",
    "        df = remove_outliers(df)   # Remove outliers\n",
    "        \n",
    "    if remove_duplicates_var == 1:\n",
    "        df = remove_duplicates(df)   # Remove duplicates\n",
    "        \n",
    "    if encoder_var == 1:\n",
    "        df = encoder(df)   # Encoding\n",
    "        \n",
    "    if feature_ing_var == 1:\n",
    "        df = feature_ing(df)   # Feature ingeniering\n",
    "        \n",
    "    if delete_features_var == 1:\n",
    "        df, to_drop = delete_features_train(df)   # Drop features\n",
    "        #print(to_drop)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8419d16c",
   "metadata": {},
   "source": [
    "### Play sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a41ba67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_sound():\n",
    "    display(Javascript('new Audio(\"https://www.soundjay.com/button/beep-07.wav\").play()'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1ea0dc",
   "metadata": {},
   "source": [
    "## Extraction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b5e4bd6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>city</th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.01</td>\n",
       "      <td>63.1</td>\n",
       "      <td>61.0</td>\n",
       "      <td>6.34</td>\n",
       "      <td>6.27</td>\n",
       "      <td>3.98</td>\n",
       "      <td>4118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1.21</td>\n",
       "      <td>61.8</td>\n",
       "      <td>56.2</td>\n",
       "      <td>6.78</td>\n",
       "      <td>6.86</td>\n",
       "      <td>4.20</td>\n",
       "      <td>5604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.70</td>\n",
       "      <td>61.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>7.59</td>\n",
       "      <td>7.52</td>\n",
       "      <td>4.67</td>\n",
       "      <td>11848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>63.1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>6.16</td>\n",
       "      <td>6.13</td>\n",
       "      <td>3.88</td>\n",
       "      <td>3452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.62</td>\n",
       "      <td>63.4</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5.46</td>\n",
       "      <td>5.43</td>\n",
       "      <td>3.45</td>\n",
       "      <td>2310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cut  color  clarity  city  carat  depth  table     x     y     z  price\n",
       "0    4      1        3     1   1.01   63.1   61.0  6.34  6.27  3.98   4118\n",
       "1    2      6        4     9   1.21   61.8   56.2  6.78  6.86  4.20   5604\n",
       "2    3      4        2     2   1.70   61.8   61.0  7.59  7.52  4.67  11848\n",
       "3    4      3        3     1   0.90   63.1   55.0  6.16  6.13  3.88   3452\n",
       "4    4      0        4     4   0.62   63.4   55.0  5.46  5.43  3.45   2310"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamond_train_df = pd.read_csv(\"../data/train/diamond_train_df_Nearest_all_features_1knn_umap.csv\")\n",
    "diamond_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4e502d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13485, 11)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamond_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62abb140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>F</td>\n",
       "      <td>SI1</td>\n",
       "      <td>62.7</td>\n",
       "      <td>60.0</td>\n",
       "      <td>5.82</td>\n",
       "      <td>5.89</td>\n",
       "      <td>3.67</td>\n",
       "      <td>Amsterdam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.20</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>J</td>\n",
       "      <td>VS1</td>\n",
       "      <td>61.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>6.81</td>\n",
       "      <td>6.89</td>\n",
       "      <td>4.18</td>\n",
       "      <td>Surat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.57</td>\n",
       "      <td>Premium</td>\n",
       "      <td>H</td>\n",
       "      <td>SI1</td>\n",
       "      <td>62.2</td>\n",
       "      <td>61.0</td>\n",
       "      <td>7.38</td>\n",
       "      <td>7.32</td>\n",
       "      <td>4.57</td>\n",
       "      <td>Kimberly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.90</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>F</td>\n",
       "      <td>SI1</td>\n",
       "      <td>63.8</td>\n",
       "      <td>54.0</td>\n",
       "      <td>6.09</td>\n",
       "      <td>6.13</td>\n",
       "      <td>3.90</td>\n",
       "      <td>Kimberly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.50</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>F</td>\n",
       "      <td>VS1</td>\n",
       "      <td>62.9</td>\n",
       "      <td>58.0</td>\n",
       "      <td>5.05</td>\n",
       "      <td>5.09</td>\n",
       "      <td>3.19</td>\n",
       "      <td>Amsterdam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  carat        cut color clarity  depth  table     x     y     z  \\\n",
       "0   0   0.79  Very Good     F     SI1   62.7   60.0  5.82  5.89  3.67   \n",
       "1   1   1.20      Ideal     J     VS1   61.0   57.0  6.81  6.89  4.18   \n",
       "2   2   1.57    Premium     H     SI1   62.2   61.0  7.38  7.32  4.57   \n",
       "3   3   0.90  Very Good     F     SI1   63.8   54.0  6.09  6.13  3.90   \n",
       "4   4   0.50  Very Good     F     VS1   62.9   58.0  5.05  5.09  3.19   \n",
       "\n",
       "        city  \n",
       "0  Amsterdam  \n",
       "1      Surat  \n",
       "2   Kimberly  \n",
       "3   Kimberly  \n",
       "4  Amsterdam  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamond_test_df = pd.read_csv(\"../data/test/diamonds_test.csv\")\n",
    "diamond_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "df5228a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40455, 12)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamond_train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8393b91b",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4c8b40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame()\n",
    "\n",
    "# Definir las columnas con los nombres deseados\n",
    "column_names = ['model', 'cv_score', 'prediction', 'drop_zeros_var', 'imputation_var', 'remove_outliers_var', \n",
    "                'remove_duplicates_var', 'encoder_var', 'feature_ing_var', 'delete_features_var', 'cut', 'color', 'clarity', \n",
    "                'city', 'carat', 'depth', 'table', 'x', 'y', 'z', 'depth_mm', 'avg_girdle', 'table_mm', 'table_depth', 'xyz']\n",
    "\n",
    "# Asignar las columnas al DataFrame\n",
    "result_df = result_df.reindex(columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "613f14f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def automate_features_choice(df, pipelines, models, result_df):\n",
    "    # Combinations\n",
    "    cut         = [1]\n",
    "    color       = [1]   # [0, 1]\n",
    "    clarity     = [1]\n",
    "    city        = [1]\n",
    "    carat       = [1]\n",
    "    depth       = [1]\n",
    "    table       = [1]\n",
    "    x           = [1]\n",
    "    y           = [1]\n",
    "    z           = [1]\n",
    "    depth_mm    = [0]\n",
    "    avg_girdle  = [0]\n",
    "    table_mm    = [0]\n",
    "    table_depth = [0]\n",
    "    xyz         = [0]\n",
    "    \n",
    "\n",
    "    # Generar todas las combinaciones posibles\n",
    "    combinations_features = itertools.product(cut, color, clarity, city, carat, depth, table, x, y, z, depth_mm, \n",
    "                                              avg_girdle, table_mm, table_depth, xyz)\n",
    "\n",
    "    #results = []\n",
    "    for comb in combinations_features:\n",
    "        #start_time = time.time()\n",
    "        \n",
    "        # Transform train data\n",
    "        df_transform = version1_without_scaler2(df,\n",
    "                                                drop_zeros_var=1,\n",
    "                                                imputation_var=0,\n",
    "                                                remove_outliers_var=1,\n",
    "                                                remove_duplicates_var=1,\n",
    "                                                feature_ing_var=1,\n",
    "                                                delete_features_var=0)\n",
    "        \n",
    "        # Obtain the features to train the model\n",
    "        cut, color, clarity, city, carat, depth, table, x, y, z, depth_mm,\\\n",
    "            avg_girdle, table_mm, table_depth, xyz = comb\n",
    "        \n",
    "        # List of all possible feature names\n",
    "        features_to_train = []\n",
    "        all_features = ['cut', 'color', 'clarity', 'city', 'carat', 'depth', 'table', 'x', 'y', 'z', 'depth_mm', \n",
    "                       'avg_girdle', 'table_mm', 'table_depth', 'xyz']\n",
    "        \n",
    "        # Iterate over features and add them to variables_with_value_1 if they have a value of 1\n",
    "        for feature in all_features:\n",
    "            if locals()[feature] == 1:\n",
    "                features_to_train.append(feature)\n",
    "\n",
    "        # splitting the dataset in test and train data . The prece will be the Target and the other columns the features\n",
    "        X = df_transform[features_to_train]\n",
    "        y = df_transform['price']\n",
    "        \n",
    "        # There are combinations in which all values are zero, in that case it isn't necessary train model\n",
    "        if df_transform.shape[1] >= 1:\n",
    "            # Split data\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=42)\n",
    "        \n",
    "            # Fit our models to the training data\n",
    "            for i in pipelines :\n",
    "                i.fit(X_train , y_train)\n",
    "\n",
    "            cv_results = []\n",
    "            for i, model in enumerate(pipelines):\n",
    "                # Cross validation\n",
    "                cv_score = cross_val_score(model, X_train, y_train, scoring=\"neg_root_mean_squared_error\", cv=5)\n",
    "                cv_results.append(cv_score)\n",
    "\n",
    "                # Test the result\n",
    "                pred = model.predict(X_test)\n",
    "\n",
    "                # Create list with featers used\n",
    "                features_value_list = list(comb)\n",
    "                \n",
    "                # Create list with process parameters\n",
    "                cv_score_mean = abs(np.mean(cv_results))\n",
    "                rmse = np.sqrt(metrics.mean_squared_error(y_test, pred))\n",
    "                process_list = [model, cv_score_mean, rmse, 1, 0, 1, 1, 1, 1, 0]\n",
    "                \n",
    "                # Create complete list\n",
    "                registros = process_list + features_value_list\n",
    "                \n",
    "                # Store the results in the results dataframe\n",
    "                result_df.loc[len(result_df.index)] = registros\n",
    "                print(model, rmse, comb)\n",
    "                \n",
    "            #end_time = time.time()\n",
    "            #print(\"Execution time: \", end_time - start_time)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4074158f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler_5', StandardScaler()),\n",
      "                ('rf_classifier', RandomForestRegressor())]) 561.9874434455998 (1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1)\n",
      "CPU times: total: 2min 26s\n",
      "Wall time: 2min 27s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>cv_score</th>\n",
       "      <th>prediction</th>\n",
       "      <th>drop_zeros_var</th>\n",
       "      <th>imputation_var</th>\n",
       "      <th>remove_outliers_var</th>\n",
       "      <th>remove_duplicates_var</th>\n",
       "      <th>encoder_var</th>\n",
       "      <th>feature_ing_var</th>\n",
       "      <th>delete_features_var</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>city</th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>depth_mm</th>\n",
       "      <th>avg_girdle</th>\n",
       "      <th>table_mm</th>\n",
       "      <th>table_depth</th>\n",
       "      <th>xyz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(StandardScaler(), (DecisionTreeRegressor(max_...</td>\n",
       "      <td>567.496672</td>\n",
       "      <td>555.614935</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(StandardScaler(), (DecisionTreeRegressor(max_...</td>\n",
       "      <td>572.976981</td>\n",
       "      <td>557.117982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(StandardScaler(), (DecisionTreeRegressor(max_...</td>\n",
       "      <td>572.404492</td>\n",
       "      <td>557.922636</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(StandardScaler(), (DecisionTreeRegressor(max_...</td>\n",
       "      <td>568.553369</td>\n",
       "      <td>558.481132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(StandardScaler(), (DecisionTreeRegressor(max_...</td>\n",
       "      <td>569.813371</td>\n",
       "      <td>558.987327</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(StandardScaler(), (DecisionTreeRegressor(max_...</td>\n",
       "      <td>571.544427</td>\n",
       "      <td>559.839550</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(StandardScaler(), (DecisionTreeRegressor(max_...</td>\n",
       "      <td>567.880659</td>\n",
       "      <td>561.987443</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(StandardScaler(), (DecisionTreeRegressor(max_...</td>\n",
       "      <td>1380.499696</td>\n",
       "      <td>1358.302937</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>-1381.388260</td>\n",
       "      <td>1360.670588</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model     cv_score  \\\n",
       "2  (StandardScaler(), (DecisionTreeRegressor(max_...   567.496672   \n",
       "3  (StandardScaler(), (DecisionTreeRegressor(max_...   572.976981   \n",
       "4  (StandardScaler(), (DecisionTreeRegressor(max_...   572.404492   \n",
       "7  (StandardScaler(), (DecisionTreeRegressor(max_...   568.553369   \n",
       "6  (StandardScaler(), (DecisionTreeRegressor(max_...   569.813371   \n",
       "5  (StandardScaler(), (DecisionTreeRegressor(max_...   571.544427   \n",
       "8  (StandardScaler(), (DecisionTreeRegressor(max_...   567.880659   \n",
       "1  (StandardScaler(), (DecisionTreeRegressor(max_...  1380.499696   \n",
       "0                                      Random Forest -1381.388260   \n",
       "\n",
       "    prediction  drop_zeros_var  imputation_var  remove_outliers_var  \\\n",
       "2   555.614935               0               0                    1   \n",
       "3   557.117982               0               0                    1   \n",
       "4   557.922636               0               0                    1   \n",
       "7   558.481132               0               0                    1   \n",
       "6   558.987327               0               0                    1   \n",
       "5   559.839550               0               0                    1   \n",
       "8   561.987443               1               0                    1   \n",
       "1  1358.302937               0               0                    1   \n",
       "0  1360.670588               0               0                    1   \n",
       "\n",
       "   remove_duplicates_var  encoder_var  feature_ing_var  delete_features_var  \\\n",
       "2                      1            1                1                    0   \n",
       "3                      1            1                1                    0   \n",
       "4                      1            1                1                    0   \n",
       "7                      1            1                1                    0   \n",
       "6                      1            1                1                    0   \n",
       "5                      1            1                1                    0   \n",
       "8                      1            1                1                    0   \n",
       "1                      1            1                1                    0   \n",
       "0                      1            1                1                    0   \n",
       "\n",
       "   cut  color  clarity  city  carat  depth  table  x  y  z  depth_mm  \\\n",
       "2    1      1        1     1      1      1      1  1  1  1         0   \n",
       "3    0      1        1     0      1      0      1  1  1  1         0   \n",
       "4    0      1        1     0      1      0      0  1  1  1         0   \n",
       "7    1      1        1     1      1      1      0  1  1  1         0   \n",
       "6    1      1        1     1      1      1      0  1  1  1         0   \n",
       "5    0      1        1     0      1      0      0  1  1  1         0   \n",
       "8    1      1        1     1      1      1      1  0  0  0         0   \n",
       "1    0      0        0     0      1      0      1  1  1  1         1   \n",
       "0    0      0        0     0      1      0      1  1  1  1         1   \n",
       "\n",
       "   avg_girdle  table_mm  table_depth  xyz  \n",
       "2           0         0            0    0  \n",
       "3           0         0            0    0  \n",
       "4           0         1            0    0  \n",
       "7           0         1            0    0  \n",
       "6           1         1            0    0  \n",
       "5           1         1            0    0  \n",
       "8           0         0            0    1  \n",
       "1           1         1            1    0  \n",
       "0           1         1            1    0  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pipelines = [rf_pipeline]   #[lr_pipeline, knn_pipline, dt_pipeline, rf_pipeline, xgb_pipeline]\n",
    "models = ['Random Forest']   #['Linear Regression', 'KNN', 'Decision Tree', 'Random Forest', 'XGB']\n",
    "\n",
    "# Execute functions and sort data\n",
    "result_df = automate_features_choice(diamond_train_df, pipelines, models, result_df)\n",
    "#play_sound()\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "result_df_sorted = result_df.sort_values(by='prediction')\n",
    "result_df_sorted.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c021297a",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "089a9c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "carat_log      1.920812\n",
       "carat          1.915878\n",
       "x              1.471532\n",
       "y              1.470174\n",
       "xyz            1.454501\n",
       "z              1.425507\n",
       "avg_girdle     1.421155\n",
       "table_mm       1.102496\n",
       "clarity        0.349953\n",
       "color          0.276316\n",
       "cut            0.099420\n",
       "table          0.053149\n",
       "depth_mm       0.044567\n",
       "table_depth    0.039373\n",
       "depth          0.028235\n",
       "city           0.003853\n",
       "Name: MI Scores, dtype: float64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observe the non-linear relation between features\n",
    "X = transformed_df.copy()\n",
    "y = X.pop(\"price\")\n",
    "\n",
    "def make_mi_scores(X, y):\n",
    "    mi_scores = mutual_info_regression(X, y)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index = X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "\n",
    "mi_scores = make_mi_scores(X, y)\n",
    "mi_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1dddf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate log\n",
    "def calculate_log(df, name):\n",
    "    list_log= []\n",
    "    for i in df['carat']:\n",
    "        list_log.append(math.log(i))\n",
    "    \n",
    "    new_name = name + '_log'\n",
    "    df[new_name] = list_log\n",
    "    return df\n",
    "\n",
    "# Funtion to classify diamond shape\n",
    "def classify_shape(df):\n",
    "    shape = []\n",
    "    for i in df['table'].index:\n",
    "        if 54<df['table'][i]<57 and 61<df['depth'][i]<62.5:\n",
    "            shape.append('Round')\n",
    "        elif 52<df['table'][i]<60 and 60<df['depth'][i]<68:\n",
    "            shape.append('Oval')\n",
    "        elif 63<df['table'][i]<69 and 69<df['depth'][i]<76:\n",
    "            shape.append('Princess')\n",
    "        elif 58<df['table'][i]<63 and 58<df['depth'][i]<66:\n",
    "            shape.append('Cushion')\n",
    "        else:\n",
    "            shape.append('others')\n",
    "            \n",
    "    df['shape'] = shape\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9c1206",
   "metadata": {},
   "source": [
    "## Transform and train diamond_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7cebc71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>city</th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>price</th>\n",
       "      <th>shape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>62.6</td>\n",
       "      <td>60.0</td>\n",
       "      <td>6.10</td>\n",
       "      <td>6.14</td>\n",
       "      <td>3.83</td>\n",
       "      <td>3950</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.81</td>\n",
       "      <td>63.1</td>\n",
       "      <td>59.0</td>\n",
       "      <td>5.85</td>\n",
       "      <td>5.79</td>\n",
       "      <td>3.67</td>\n",
       "      <td>2809</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>62.5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>5.89</td>\n",
       "      <td>5.94</td>\n",
       "      <td>3.69</td>\n",
       "      <td>2806</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1.14</td>\n",
       "      <td>61.5</td>\n",
       "      <td>57.0</td>\n",
       "      <td>6.70</td>\n",
       "      <td>6.73</td>\n",
       "      <td>4.13</td>\n",
       "      <td>5392</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1.33</td>\n",
       "      <td>61.3</td>\n",
       "      <td>57.0</td>\n",
       "      <td>7.11</td>\n",
       "      <td>7.08</td>\n",
       "      <td>4.35</td>\n",
       "      <td>6118</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cut  color  clarity  city  carat  depth  table     x     y     z  price  \\\n",
       "0    4      2        2     0   0.90   62.6   60.0  6.10  6.14  3.83   3950   \n",
       "1    4      2        2     1   0.81   63.1   59.0  5.85  5.79  3.67   2809   \n",
       "2    4      3        2     0   0.81   62.5   60.0  5.89  5.94  3.69   2806   \n",
       "3    2      6        4    10   1.14   61.5   57.0  6.70  6.73  4.13   5392   \n",
       "4    2      6        4    10   1.33   61.3   57.0  7.11  7.08  4.35   6118   \n",
       "\n",
       "   shape  \n",
       "0      0  \n",
       "1      1  \n",
       "2      0  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform\n",
    "transformed_df = classify_shape(diamond_train_df)\n",
    "transformed_df = encoder(transformed_df)\n",
    "transformed_df = drop_zeros(transformed_df)\n",
    "#transformed_df = imputation(transformed_df)\n",
    "transformed_df = remove_outliers(transformed_df)\n",
    "transformed_df = remove_duplicates(transformed_df)\n",
    "transformed_df = feature_ing(transformed_df)\n",
    "\n",
    "# default = ['cut', 'color', 'clarity', 'city', 'carat', 'depth', 'table', 'x', 'y', 'z', 'price']\n",
    "\n",
    "all_features = ['cut', 'color', 'clarity', 'city', 'depth','carat', 'depth', 'table', 'x', 'y', 'z', 'depth_mm', \n",
    "                'avg_girdle', 'table_mm', 'table_depth', 'xyz', 'price', 'carat_log', 'x_log', 'y_log',\n",
    "                'z_log', 'ratio_length_width', 'ratio_length_width_depth', 'volume', 'density']\n",
    "selection_features = ['cut', 'color', 'clarity', 'city', 'carat', 'depth', 'table', 'x', 'y', 'z', 'price', 'shape']\n",
    "\n",
    "\n",
    "transformed_df = calculate_log(transformed_df, 'carat')\n",
    "transformed_df = calculate_log(transformed_df, 'x')\n",
    "transformed_df = calculate_log(transformed_df, 'y')\n",
    "transformed_df = calculate_log(transformed_df, 'z')\n",
    "\n",
    "transformed_df['ratio_length_width'] = transformed_df['x']/transformed_df['y']\n",
    "transformed_df['ratio_length_width_depth'] = transformed_df['x']/transformed_df['y']/transformed_df['z']\n",
    "transformed_df['volume'] = transformed_df['x']*transformed_df['y']*transformed_df['z']\n",
    "transformed_df['density'] = transformed_df['carat']/transformed_df['volume']\n",
    "\n",
    "#Doesn't make sense to have diamonds with width and depth higher than 20:\n",
    "#transformed_df = transformed_df.loc[~(transformed_df['carat_log'] == 0 )]\n",
    "\n",
    "transformed_df_2 = transformed_df[selection_features]\n",
    "transformed_df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5038c779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters:  {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 500, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}  | cv_score_mean: 590.2481135772182  | rmse: 571.9045673014758\n",
      "CPU times: total: 5min 41s\n",
      "Wall time: 46.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\"\n",
    "# Transform\n",
    "transformed_df = encoder(diamond_train_df)\n",
    "transformed_df = drop_zeros(transformed_df)\n",
    "transformed_df = remove_outliers(transformed_df)\n",
    "transformed_df = remove_duplicates(transformed_df)\n",
    "transformed_df = feature_ing(transformed_df)\n",
    "#scaled_df = stardard_scale_test(transformed_df)\n",
    "\n",
    "X = transformed_df.drop('price',axis = 1)\n",
    "y = transformed_df['price']\n",
    "\"\"\"\n",
    "X = transformed_df_2.drop('price',axis = 1)\n",
    "y = transformed_df_2['price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=42)\n",
    "\n",
    "# Model\n",
    "\n",
    "model = RandomForestRegressor(random_state=42,\n",
    "                              n_estimators=500,\n",
    "                              #max_features='log2',\n",
    "                              n_jobs=-1)\n",
    "\"\"\"\n",
    "model = GradientBoostingRegressor(random_state = 42,\n",
    "                                  n_estimators=100)\n",
    "\"\"\"\n",
    "\n",
    "# Cross validation\n",
    "cv_results = []\n",
    "cv_score = cross_val_score(model, X_train, y_train, scoring=\"neg_root_mean_squared_error\", cv=5)\n",
    "cv_results.append(cv_score)\n",
    "\n",
    "# Train\n",
    "model.fit(X_train, y_train)\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "# Prints\n",
    "hyperparameters = model.get_params()\n",
    "cv_score_mean = abs(np.mean(cv_results))\n",
    "rmse = mean_squared_error(y_test, y_pred)**0.5\n",
    "\n",
    "print('Hyperparameters: ', hyperparameters, ' | cv_score_mean:', cv_score_mean, ' | rmse:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "360d1fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_optimaze = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d12282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features = ['cut', 'color', 'clarity', 'city', 'depth', 'table', 'carat_log', 'x_log', 'y_log', 'z_log',\n",
    "#             'ratio_length_width', 'ratio_length_width_depth', 'volume', 'density', 'price']\n",
    "# encoding, drop_zeros, remove_outliers y remove_duplicates | n_stimators=500 \n",
    "# Submission = 597\n",
    "Hyperparameters:  {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 500, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}  \n",
    "    | cv_score_mean: 563.6224504060208  | rmse: 541.8872683394235\n",
    "CPU times: total: 17min 7s\n",
    "Wall time: 2min 22s\n",
    "\n",
    "# Features = ['cut', 'color', 'clarity', 'city', 'depth', 'table', 'carat_log', \n",
    "#             'ratio_length_width', 'ratio_length_width_depth', 'volume', 'density', 'price']\n",
    "# encoding, drop_zeros, remove_outliers y remove_duplicates | n_stimators=500\n",
    "# Submission = 597\n",
    "Hyperparameters:  {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 500, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}  \n",
    "    | cv_score_mean: 563.1380099851094  | rmse: 541.9037907071685\n",
    "CPU times: total: 14min 32s\n",
    "Wall time: 1min 56s\n",
    "\n",
    "# Features = ['cut', 'color', 'clarity', 'city', 'depth', 'table','x', 'y', 'z', 'carat_log', \n",
    "#             'ratio_length_width', 'ratio_length_width_depth', 'volume', 'density', 'price']\n",
    "# encoding, drop_zeros, remove_outliers y remove_duplicates | n_stimators=500 \n",
    "Hyperparameters:  {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 500, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}  \n",
    "    | cv_score_mean: 568.2830813092132  | rmse: 545.7160325766089\n",
    "CPU times: total: 18min 18s\n",
    "Wall time: 2min 32s\n",
    "\n",
    "# Features = ['cut', 'color', 'clarity', 'carat_log', 'depth', 'table', 'price']\n",
    "# encoding, imputation, remove_outliers y remove_duplicates | n_stimators=500\n",
    "# Submission = 552\n",
    "Hyperparameters:  {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 500, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}  \n",
    "    | cv_score_mean: 578.5952143324417  | rmse: 552.891156245962\n",
    "CPU times: total: 4min 37s\n",
    "Wall time: 40.2 s\n",
    "\n",
    "# Features de serie, encoding, drop_zeros, remove_outliers y remove_duplicates | n_stimators=500\n",
    "# Submission = 543---------------------------------------------------------------\n",
    "Hyperparameters:  {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 500, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}  \n",
    "    | cv_score_mean: 570.0212938830194  | rmse: 552.9419513838835  | rmse_2: 552.9419513838835\n",
    "CPU times: total: 9min 28s\n",
    "Wall time: 1min 22s\n",
    "    \n",
    "# Features de serie, encoding, drop_zeros, remove_outliers y remove_duplicates | n_stimators=600\n",
    "Hyperparameters:  {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 600, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}  \n",
    "    | cv_score_mean: 569.6888950649824  | rmse: 553.1880851479532  | rmse_2: 553.1880851479532\n",
    "CPU times: total: 11min 53s\n",
    "Wall time: 1min 40s\n",
    "\n",
    "# Features de serie, encoding, drop_zeros, remove_outliers y remove_duplicates | n_stimators=400\n",
    "Hyperparameters:  {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 300, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}  \n",
    "    | cv_score_mean: 570.392820611711  | rmse: 553.2600932696147  | rmse_2: 553.2600932696147\n",
    "CPU times: total: 4min 35s\n",
    "Wall time: 42.8 s\n",
    "\n",
    "# Features = ['cut', 'color', 'clarity', 'city', 'depth', 'table', 'x', 'y', 'z', 'carat_log', 'price']\n",
    "# encoding, drop_zeros, remove_outliers y remove_duplicates | n_stimators=500 \n",
    "Hyperparameters:  {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 500, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}  \n",
    "    | cv_score_mean: 570.336771427553  | rmse: 553.3567161129744\n",
    "CPU times: total: 9min 54s\n",
    "Wall time: 1min 32s\n",
    "\n",
    "# Features = ['cut', 'color', 'clarity', 'city', 'depth', 'table', 'x', 'y', 'z', 'carat_log', 'price']\n",
    "# encoding, drop_zeros, remove_outliers y remove_duplicates | n_stimators=500 \n",
    "Hyperparameters:  {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 500, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}  \n",
    "    | cv_score_mean: 570.2595671275265  | rmse: 553.4054287603929\n",
    "CPU times: total: 9min 10s\n",
    "Wall time: 1min 14s\n",
    "    \n",
    "# Features de serie, encoding, drop_zeros, remove_outliers y remove_duplicates | n_stimators=400\n",
    "Hyperparameters:  {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}  \n",
    "    | cv_score_mean: 573.2463024252991  | rmse: 553.7944242193641  | rmse_2: 553.7944242193641\n",
    "CPU times: total: 1min 27s\n",
    "Wall time: 13.4 s\n",
    "    \n",
    "# Features de serie, encoding, drop_zeros, remove_outliers y remove_duplicates | n_stimators=400\n",
    "Hyperparameters:  {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}  \n",
    "    | cv_score_mean: 574.2712643507491  | rmse: 554.488321315124  | rmse_2: 554.488321315124\n",
    "CPU times: total: 1min 23s\n",
    "Wall time: 13.1 s\n",
    "\n",
    "# Features = ['cut', 'color', 'clarity', 'city', 'carat', 'depth', 'table', 'x', 'y', 'z', 'price', 'shape']\n",
    "# encoding, drop_zeros, remove_outliers y remove_duplicates | n_stimators=500\n",
    "# Submission = 542 ----------------------------------------------------------\n",
    "Hyperparameters:  {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 500, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}  \n",
    "    | cv_score_mean: 570.1513571076711  | rmse: 554.7242488195719\n",
    "CPU times: total: 10min 2s\n",
    "Wall time: 1min 25s\n",
    "    \n",
    "# Features de serie, encoding, drop_zeros, remove_outliers y remove_duplicates | n_stimators=400\n",
    "Hyperparameters:  {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 400, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}  \n",
    "    | cv_score_mean: 568.2230549678686  | rmse: 555.2393808873512  | rmse_2: 555.2393808873512\n",
    "CPU times: total: 15min 42s\n",
    "Wall time: 2min 12s\n",
    "    \n",
    "# Features = ['cut', 'color', 'clarity', 'city', 'carat', 'table','x', 'y', 'z', 'carat_log', 'price'] \n",
    "# encoding, drop_zeros, remove_outliers y remove_duplicates | n_stimators=500 \n",
    "Hyperparameters:  {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 500, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}  \n",
    "    | cv_score_mean: 571.09845582581  | rmse: 555.2875203635209  | rmse_2: 555.2875203635209\n",
    "CPU times: total: 8min 40s\n",
    "Wall time: 1min 11s\n",
    "\n",
    "# Features = ['cut', 'color', 'clarity', 'city', 'carat_log', 'table','x', 'y', 'z', 'price']\n",
    "# encoding, drop_zeros, remove_outliers y remove_duplicates | n_stimators=50\n",
    "Hyperparameters:  {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 500, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}  \n",
    "    | cv_score_mean: 570.9756633240581  | rmse: 555.6053281565353  | rmse_2: 555.6053281565353\n",
    "CPU times: total: 8min 43s\n",
    "Wall time: 1min 15s\n",
    "    \n",
    "# Features = ['cut', 'color', 'clarity', 'city', 'carat', 'depth', 'x', 'y', 'z','avg_girdle', 'table_mm', 'xyz', 'price'] \n",
    "# encoding, drop_zeros, remove_outliers y remove_duplicates | n_stimators=500   \n",
    "Hyperparameters:  {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 500, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}  \n",
    "    | cv_score_mean: 567.5032514631432  | rmse: 555.7750839709606  | rmse_2: 555.7750839709606\n",
    "CPU times: total: 14min 5s\n",
    "Wall time: 1min 53s\n",
    "\n",
    "# Features = ['cut', 'color', 'clarity', 'carat_log', 'table','x', 'y', 'z', 'price']\n",
    "# encoding, drop_zeros, remove_outliers y remove_duplicates | n_stimators=50\n",
    "Hyperparameters:  {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 500, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}  | cv_score_mean: 569.945980050026  | rmse: 556.4799516795906  | rmse_2: 556.4799516795906\n",
    "CPU times: total: 6min 35s\n",
    "Wall time: 55 s\n",
    "\n",
    "# Features = ['cut', 'color', 'clarity', 'city', 'carat', 'depth', 'x', 'y', 'z', 'table_mm', 'price']\n",
    "# encoding, drop_zeros, remove_outliers y remove_duplicates | n_stimators=50\n",
    "Hyperparameters:  {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 500, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}  \n",
    "    | cv_score_mean: 570.4899544500876  | rmse: 556.0081586081567  | rmse_2: 556.0081586081567\n",
    "CPU times: total: 10min 40s\n",
    "Wall time: 1min 30s\n",
    "\n",
    "# Features = ['cut', 'color', 'clarity', 'city', 'carat', 'depth', 'x', 'y', 'z', 'avg_girdle', 'table_mm', 'price']\n",
    "# encoding, drop_zeros, remove_outliers y remove_duplicates | n_stimators=50\n",
    "Hyperparameters:  {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 500, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}  \n",
    "    | cv_score_mean: 569.6400678426654  | rmse: 556.1522654109002  | rmse_2: 556.1522654109002\n",
    "CPU times: total: 12min 2s\n",
    "Wall time: 1min 44s\n",
    "\n",
    "# Features = [['cut', 'color', 'clarity', 'city', 'carat', 'depth', 'avg_girdle', 'table_mm', 'xyz', 'price']] \n",
    "# encoding, drop_zeros, remove_outliers y remove_duplicates | n_stimators=500 \n",
    "Hyperparameters:  {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 500, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}  \n",
    "    | cv_score_mean: 571.0132381609183  | rmse: 562.8086785378399  | rmse_2: 562.8086785378399\n",
    "CPU times: total: 10min 44s\n",
    "Wall time: 1min 26s\n",
    "\n",
    "# Features = ['cut', 'color', 'clarity', 'city', 'carat_log', 'depth', 'table','x_log', 'y_log', 'z_log', 'price']\n",
    "# encoding, drop_zeros, remove_outliers y remove_duplicates | n_stimators=500 \n",
    "Hyperparameters:  {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 500, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}  \n",
    "    | cv_score_mean: 578.4665781312609  | rmse: 563.1005194121811\n",
    "CPU times: total: 7min 48s\n",
    "Wall time: 1min 7s\n",
    "    \n",
    "# Features de serie y solo encoding | n_stimators=400\n",
    "Hyperparameters:  {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}  \n",
    "    | cv_score_mean: 568.7680257934356  | rmse: 587.9591159724442  | rmse_2: 587.9591159724442\n",
    "CPU times: total: 1min 2s\n",
    "Wall time: 1min 3s\n",
    "    \n",
    "# Features = ['color', 'carat', 'table', 'x', 'y', 'z', 'price'] \n",
    "# encoding, drop_zeros, remove_outliers y remove_duplicates | n_stimators=500\n",
    "Hyperparameters:  {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 500, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}  \n",
    "    | cv_score_mean: 1193.7263388731408  | rmse: 1176.9075341911703  | rmse_2: 1176.9075341911703\n",
    "CPU times: total: 6min 9s\n",
    "Wall time: 53.4 s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1243e8ff",
   "metadata": {},
   "source": [
    "## Transform test data and obtain the prediction to upload in kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "081caad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform\n",
    "def transformation_data(df, type_data):\n",
    "    trans_df = classify_shape(df)\n",
    "    trans_df = encoder(trans_df)\n",
    "    trans_df = imputation(trans_df)\n",
    "\n",
    "    if type_data == 'train_data':\n",
    "        #trans_df = drop_zeros(trans_df)\n",
    "        trans_df = remove_outliers(trans_df)\n",
    "        trans_df = remove_duplicates(trans_df)\n",
    "        selection_features = ['cut', 'color', 'clarity', 'city', 'carat', 'depth', 'table', 'x', 'y', 'z', 'shape', 'price']\n",
    "        \n",
    "        #selection_features = ['cut', 'color', 'clarity', 'city', 'carat', 'depth', 'table','x', 'y', 'z', 'price']\n",
    "    if type_data == 'test_data':\n",
    "        selection_features = ['cut', 'color', 'clarity', 'city', 'carat', 'depth', 'table', 'x', 'y', 'z', 'shape']\n",
    "        #selection_features = ['cut', 'color', 'clarity', 'city', 'carat', 'depth', 'table', 'x', 'y', 'z']\n",
    "    trans_df = feature_ing(trans_df)\n",
    "\n",
    "    trans_df = calculate_log(trans_df, 'carat')\n",
    "    trans_df = calculate_log(trans_df, 'x')\n",
    "    trans_df = calculate_log(trans_df, 'y')\n",
    "    trans_df = calculate_log(trans_df, 'z')\n",
    "\n",
    "\n",
    "    trans_df['ratio_length_width'] = trans_df['x']/trans_df['y']\n",
    "    trans_df['ratio_length_width_depth'] = trans_df['x']/trans_df['y']/trans_df['z']\n",
    "    trans_df['volume'] = trans_df['x']*trans_df['y']*trans_df['z']\n",
    "    trans_df['density'] = trans_df['carat']/trans_df['volume']\n",
    "    \n",
    "    trans_df_2 = trans_df[selection_features]\n",
    "    trans_df_2.head()\n",
    "    \n",
    "    return trans_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "75611df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13485, 12)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamond_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1975902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters:  {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 500, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}  | cv_score_mean: 610.2152060900632\n",
      "CPU times: total: 3min 8s\n",
      "Wall time: 26.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Transform diamond_train_df\n",
    "train_df = transformation_data(diamond_train_df, 'train_data')\n",
    "X_train = train_df.drop('price',axis = 1)\n",
    "y_train = train_df['price']\n",
    "\n",
    "# Transform diamond_test_df\n",
    "X_test = transformation_data(diamond_test_df, 'test_data')\n",
    "\n",
    "# Model\n",
    "model = RandomForestRegressor(random_state=42,\n",
    "                              n_estimators=500,\n",
    "                              #max_features='log2',\n",
    "                              n_jobs=-1)\n",
    "\n",
    "# Cross validation\n",
    "cv_results = []\n",
    "cv_score = cross_val_score(model, X_train, y_train, scoring=\"neg_root_mean_squared_error\", cv=5)\n",
    "cv_results.append(cv_score)\n",
    "\n",
    "# Train\n",
    "model.fit(X_train, y_train)\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "# Prints\n",
    "hyperparameters = model.get_params()\n",
    "cv_score_mean = abs(np.mean(cv_results))\n",
    "#rmse = mean_squared_error(y_test, y_pred)**0.5\n",
    "\n",
    "print('Hyperparameters: ', hyperparameters, ' | cv_score_mean:', cv_score_mean)   #, ' | rmse:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8121248e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13485"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff7e5877",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_df = pd.DataFrame(y_pred)\n",
    "y_pred_df.reset_index(inplace=True)\n",
    "y_pred_df.columns = ['id', 'price']\n",
    "y_pred_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467b5de9",
   "metadata": {},
   "source": [
    "# Optimize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cab3ff37",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [500],  # Number of trees in the forest.\n",
    "              'max_depth': [None, 3, 10],  # Maximum depth of the trees.\n",
    "              'min_samples_split': [2, 10],  # Minimum number of samples required to split an internal node.\n",
    "              'min_samples_leaf': [1, 4],  # Minimum number of samples required to be at a leaf node.\n",
    "              'max_features': [None, 'sqrt', 'log2']  # Number of features to consider when looking for the best split.\n",
    "              }\n",
    "\n",
    "grid_search = GridSearchCV(model_optimaze,\n",
    "                           param_grid,\n",
    "                           cv=5,\n",
    "                           verbose=3,\n",
    "                           scoring='neg_root_mean_squared_error',\n",
    "                           n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b2cd68af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "\n",
      "\n",
      "Best hyperparameters:  {'max_depth': None, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500} \n",
      "\n",
      "Best score:  574.9872926157677 \n",
      "\n",
      "CPU times: total: 1min 42s\n",
      "Wall time: 7min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "grid_search.fit(X,y)\n",
    "\n",
    "print('\\n')\n",
    "print('Best hyperparameters: ', grid_search.best_params_, '\\n')\n",
    "print('Best score: ', -grid_search.best_score_, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f651cba0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m3_env",
   "language": "python",
   "name": "m3_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
