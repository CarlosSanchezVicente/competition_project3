{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01cf6938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Imports\n",
    "import itertools\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, StandardScaler, PolynomialFeatures\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.cluster import DBSCAN\n",
    "import umap\n",
    "\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Install sqlite as a extension of duckdb\n",
    "#duckdb.install_extension('sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eefd0b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>price</th>\n",
       "      <th>city</th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Premium</td>\n",
       "      <td>J</td>\n",
       "      <td>VS2</td>\n",
       "      <td>4268</td>\n",
       "      <td>Dubai</td>\n",
       "      <td>1.21</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>6.83</td>\n",
       "      <td>6.79</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Very Good</td>\n",
       "      <td>H</td>\n",
       "      <td>VS2</td>\n",
       "      <td>505</td>\n",
       "      <td>Kimberly</td>\n",
       "      <td>0.32</td>\n",
       "      <td>63.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.38</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fair</td>\n",
       "      <td>G</td>\n",
       "      <td>VS1</td>\n",
       "      <td>2686</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>0.71</td>\n",
       "      <td>65.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5.62</td>\n",
       "      <td>5.53</td>\n",
       "      <td>3.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good</td>\n",
       "      <td>D</td>\n",
       "      <td>SI1</td>\n",
       "      <td>738</td>\n",
       "      <td>Kimberly</td>\n",
       "      <td>0.41</td>\n",
       "      <td>63.8</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.68</td>\n",
       "      <td>4.72</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>SI1</td>\n",
       "      <td>4882</td>\n",
       "      <td>Dubai</td>\n",
       "      <td>1.02</td>\n",
       "      <td>60.5</td>\n",
       "      <td>59.0</td>\n",
       "      <td>6.55</td>\n",
       "      <td>6.51</td>\n",
       "      <td>3.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cut color clarity  price       city  carat  depth  table     x     y  \\\n",
       "0    Premium     J     VS2   4268      Dubai   1.21   62.4   58.0  6.83  6.79   \n",
       "1  Very Good     H     VS2    505   Kimberly   0.32   63.0   57.0  4.35  4.38   \n",
       "2       Fair     G     VS1   2686  Las Vegas   0.71   65.5   55.0  5.62  5.53   \n",
       "3       Good     D     SI1    738   Kimberly   0.41   63.8   56.0  4.68  4.72   \n",
       "4      Ideal     G     SI1   4882      Dubai   1.02   60.5   59.0  6.55  6.51   \n",
       "\n",
       "      z  \n",
       "0  4.25  \n",
       "1  2.75  \n",
       "2  3.65  \n",
       "3  3.00  \n",
       "4  3.95  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a connection to a file called 'file.db'\n",
    "con = duckdb.connect(\"../data/train/diamonds_train.db\")\n",
    "\n",
    "# Query to extract data from database\n",
    "query_full = \"\"\"\n",
    "SELECT\n",
    "    --tra.index_id,\n",
    "    cut.cut,\n",
    "    col.color,\n",
    "    cla.clarity,\n",
    "    tra.price,\n",
    "    cit.city,\n",
    "    tra.carat,\n",
    "    dim.depth,\n",
    "    dim.table,\n",
    "    dim.x,\n",
    "    dim.y,\n",
    "    dim.z\n",
    "FROM diamonds_properties AS pro\n",
    "JOIN diamonds_cut AS cut ON pro.cut_id = cut.cut_id\n",
    "JOIN diamonds_color AS col ON pro.color_id = col.color_id\n",
    "JOIN diamonds_clarity AS cla ON pro.clarity_id = cla.clarity_id\n",
    "JOIN diamonds_transactional as tra ON pro.index_id = tra.index_id\n",
    "JOIN diamonds_city AS cit ON tra.city_id = cit.city_id\n",
    "JOIN diamonds_dimensions AS dim ON pro.index_id = dim.index_id\n",
    "\"\"\"\n",
    "\n",
    "df_train = con.execute(query_full).df()\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94ec156a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.79</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>F</td>\n",
       "      <td>SI1</td>\n",
       "      <td>62.7</td>\n",
       "      <td>60.0</td>\n",
       "      <td>5.82</td>\n",
       "      <td>5.89</td>\n",
       "      <td>3.67</td>\n",
       "      <td>Amsterdam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.20</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>J</td>\n",
       "      <td>VS1</td>\n",
       "      <td>61.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>6.81</td>\n",
       "      <td>6.89</td>\n",
       "      <td>4.18</td>\n",
       "      <td>Surat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.57</td>\n",
       "      <td>Premium</td>\n",
       "      <td>H</td>\n",
       "      <td>SI1</td>\n",
       "      <td>62.2</td>\n",
       "      <td>61.0</td>\n",
       "      <td>7.38</td>\n",
       "      <td>7.32</td>\n",
       "      <td>4.57</td>\n",
       "      <td>Kimberly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.90</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>F</td>\n",
       "      <td>SI1</td>\n",
       "      <td>63.8</td>\n",
       "      <td>54.0</td>\n",
       "      <td>6.09</td>\n",
       "      <td>6.13</td>\n",
       "      <td>3.90</td>\n",
       "      <td>Kimberly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.50</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>F</td>\n",
       "      <td>VS1</td>\n",
       "      <td>62.9</td>\n",
       "      <td>58.0</td>\n",
       "      <td>5.05</td>\n",
       "      <td>5.09</td>\n",
       "      <td>3.19</td>\n",
       "      <td>Amsterdam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat        cut color clarity  depth  table     x     y     z       city\n",
       "0   0.79  Very Good     F     SI1   62.7   60.0  5.82  5.89  3.67  Amsterdam\n",
       "1   1.20      Ideal     J     VS1   61.0   57.0  6.81  6.89  4.18      Surat\n",
       "2   1.57    Premium     H     SI1   62.2   61.0  7.38  7.32  4.57   Kimberly\n",
       "3   0.90  Very Good     F     SI1   63.8   54.0  6.09  6.13  3.90   Kimberly\n",
       "4   0.50  Very Good     F     VS1   62.9   58.0  5.05  5.09  3.19  Amsterdam"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"../data/test/diamonds_test.csv\")\n",
    "df_test.drop(columns='id', inplace=True)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b08880a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#type_trans = 'train' or 'test'\n",
    "\n",
    "def transformations(df, type_trans):\n",
    "    if type_trans == 'train':\n",
    "        df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    # Rename columns\n",
    "    #df.rename(columns={'x': 'length', 'y': 'width', 'depth': 'depth','table':'table_width'}, inplace=True)\n",
    "    \n",
    "    # Encode\n",
    "    cut_categories = df['cut'].unique()\n",
    "    color_categories = df['color'].unique()\n",
    "    clarity_categories = df['clarity'].unique()\n",
    "    city_categories = df['city'].unique()\n",
    "    \n",
    "    # Change to categorical\n",
    "    df['cut'] = pd.Categorical(df['cut'], categories= cut_categories, ordered=True)\n",
    "    df['color'] = pd.Categorical(df['color'], categories= color_categories, ordered=True)\n",
    "    df['clarity'] = pd.Categorical(df['clarity'], categories= clarity_categories, ordered=True)\n",
    "    df['city'] = pd.Categorical(df['city'], categories= city_categories, ordered=True)\n",
    "    \n",
    "    cat_cols = ['cut','color','clarity', 'city']\n",
    "    cat_orders = [cut_categories, color_categories, clarity_categories, city_categories]\n",
    "    encoder = OrdinalEncoder(categories=cat_orders)\n",
    "    cats_encoded = pd.DataFrame(encoder.fit_transform(df[cat_cols]), columns = ['cut_encoded','color_encoded',\n",
    "                                                                                'clarity_encoded','city_encoded'])\n",
    "    \n",
    "    # Store encoded columns\n",
    "    df_encoded = df.drop(columns=['cut','color','clarity','city']).copy()\n",
    "    df_encoded['cut_encoded'] = df['cut'].cat.codes\n",
    "    df_encoded['color_encoded'] = df['color'].cat.codes\n",
    "    df_encoded['clarity_encoded'] = df['clarity'].cat.codes\n",
    "    df_encoded['city_encoded'] = df['city'].cat.codes\n",
    "    \n",
    "    # Calculate volume\n",
    "    df['volume'] = df['z'] * df['y'] * df['z']\n",
    "    df_encoded['volume'] = df['volume']\n",
    "    \n",
    "    clean_df = df_encoded.copy()\n",
    "    if type_trans == 'train':\n",
    "        outliers_cols = ['x','y','z','table','depth','volume']\n",
    "\n",
    "        # setting values that above or lower than the whiskers in the box plot to NaNs\n",
    "        for col in outliers_cols:\n",
    "\n",
    "            data = clean_df[col]\n",
    "\n",
    "            Q1 = data.quantile(0.25)\n",
    "            Q3 = data.quantile(0.75)\n",
    "\n",
    "            IQR = Q3 - Q1\n",
    "\n",
    "            min = Q1 - (1.5 * IQR)\n",
    "            max = Q3 + (1.5 * IQR)\n",
    "\n",
    "            outliers = ( (data < min) | (data > max) )\n",
    "\n",
    "            clean_df.loc[outliers, col] = np.nan\n",
    "\n",
    "        clean_df.isna().sum()\n",
    "    \n",
    "    # Remove NaN\n",
    "    imputer = IterativeImputer(max_iter=50)\n",
    "    clean_df = pd.DataFrame(imputer.fit_transform(clean_df), columns=clean_df.columns, index=clean_df.index)\n",
    "    \n",
    "    # Change cut to cut_encoded...\n",
    "    df_all = clean_df.copy()\n",
    "    df_all[['cut','color','clarity','city']] = df[['cut','color','clarity','city']] \n",
    "    df = df_all.drop(columns=['cut_encoded','color_encoded','clarity_encoded','city_encoded'])\n",
    "    \n",
    "    # Transform dataframe\n",
    "    Skewed_Cols = clean_df[['carat','volume']].columns\n",
    "    trans_df = clean_df.copy()\n",
    "    for col in Skewed_Cols:\n",
    "        trans_df[col] = np.log(1 + trans_df[col])\n",
    "    \n",
    "    # POLYNOMICAL FEATURES\n",
    "    if type_trans == 'train':\n",
    "        price_column = trans_df['price']\n",
    "        df_ploy = trans_df.drop(columns=['price']).copy()\n",
    "    else:\n",
    "        df_ploy = trans_df\n",
    "        \n",
    "    poly = PolynomialFeatures(2)\n",
    "    ploy_data = poly.fit_transform(df_ploy)\n",
    "    df_ploy = pd.DataFrame(ploy_data, columns=poly.get_feature_names_out())\n",
    "    # Scale dataframe with polynomical\n",
    "    df_scaled = df_ploy.copy()\n",
    "    Scaler = StandardScaler()\n",
    "    scaled_data = Scaler.fit_transform(df_scaled)\n",
    "    df_scaled = pd.DataFrame(scaled_data, columns=df_scaled.columns)\n",
    "    \n",
    "    # WITHOUT POLYNOMICAL FEATURES\n",
    "    if type_trans == 'train':\n",
    "        price_column = trans_df['price']\n",
    "        org_df_scaled = trans_df.drop(columns=['price']).copy()\n",
    "    else:\n",
    "        org_df_scaled = trans_df\n",
    "        \n",
    "    Scaler = StandardScaler()\n",
    "    scaled_data = Scaler.fit_transform(org_df_scaled)\n",
    "    org_df_scaled = pd.DataFrame(scaled_data, columns=org_df_scaled.columns)\n",
    "    \n",
    "    if type_trans == 'train':\n",
    "        return df_scaled, org_df_scaled, price_column \n",
    "    else:\n",
    "        return df_scaled, org_df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "201896f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#type_trans = 'train' or 'test'\n",
    "df_train_trans, df_train_trans_no_ploy, price_column = transformations(df_train, 'train')\n",
    "df_test_trans, df_test_trans_no_ploy = transformations(df_test, 'test') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9b4b6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train_trans\n",
    "y = price_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2cddd51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "\n",
      "\n",
      "Best hyperparameters:  {'colsample_bytree': 0.75, 'gamma': 0.12, 'lambda': 0.35, 'learning_rate': 0.025, 'max_depth': 5, 'n_estimators': 1600, 'subsample': 1} \n",
      "\n",
      "Best score:  -553.1687579970476 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#param_Rodri = {'colsample_bytree': 0.95, 'gamma': 0.14, 'learning_rate': 0.012, 'max_depth': 7, 'missing': np.inf, \n",
    "#               'n_estimators': 1130, 'subsample': 0.8}\n",
    "\n",
    "param_grid = {'n_estimators': [1600],  # Number of trees in the forest.\n",
    "              'max_depth': [5],  # Maximum depth of the trees.\n",
    "              'subsample': [1],\n",
    "              'colsample_bytree': [0.75],\n",
    "              'lambda': [0.35],\n",
    "              'gamma': [0.12],\n",
    "              'learning_rate': [0.025]\n",
    "              }\n",
    "\n",
    "xgb_reg = XGBRegressor(random_state=0)\n",
    "\n",
    "xgb_grid_search = GridSearchCV(xgb_reg, param_grid, cv=3, scoring='neg_root_mean_squared_error', return_train_score=True, verbose=1, n_jobs=-1)\n",
    "\n",
    "xgb_grid_search.fit(X, y)\n",
    "\n",
    "print('\\n')\n",
    "print('Best hyperparameters: ', xgb_grid_search.best_params_, '\\n')\n",
    "print('Best score: ', xgb_grid_search.best_score_, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ff31afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'n_estimators': 1600,  # Number of trees in the forest.\n",
    "              'max_depth': 5,  # Maximum depth of the trees.\n",
    "              'subsample': 1,\n",
    "              'colsample_bytree': 0.75,\n",
    "              'lambda': 0.35,\n",
    "              'gamma': 0.12,\n",
    "              'learning_rate': 0.025,\n",
    "              'random_state':0\n",
    "              }\n",
    "xgb_model = XGBRegressor(**param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "abf7a369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters:  {'objective': 'reg:squarederror', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.75, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': 0.12, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.025, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 5, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 1600, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 0, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 1, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'lambda': 0.35}  | cv_score_mean: 550.0337589436816  | rmse: 566.2477701208646\n",
      "CPU times: total: 46.7 s\n",
      "Wall time: 8.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "\n",
    "# Cross validation\n",
    "cv_results = []\n",
    "cv_score = cross_val_score(xgb_model, X_train, y_train, scoring=\"neg_root_mean_squared_error\", cv=5)\n",
    "cv_results.append(cv_score)\n",
    "\n",
    "# Train\n",
    "xgb_model.fit(X_train,y_train)\n",
    "# Predict\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "# Prints\n",
    "hyperparameters = xgb_model.get_params()\n",
    "cv_score_mean = abs(np.mean(cv_results))\n",
    "rmse = mean_squared_error(y_test, y_pred)**0.5\n",
    "\n",
    "print('Hyperparameters: ', hyperparameters, ' | cv_score_mean:', cv_score_mean, ' | rmse:', rmse)\n",
    "\n",
    "#registers = [model_type, cv_score_mean, rmse, 0, selection_features, transformations, estimators, hyperparameters]\n",
    "#parameters_df.loc[len(parameters_df.index)] = registers\n",
    "#parameters_df.to_csv('./parameters_training/best_parameters_prediction_models.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f2fdaee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_score_mean: 552.946870263789\n"
     ]
    }
   ],
   "source": [
    "cv_results = []\n",
    "cv_score = cross_val_score(xgb_model, X, y, scoring=\"neg_root_mean_squared_error\", cv=5)\n",
    "cv_results.append(cv_score)\n",
    "print('cv_score_mean:', cv_score_mean)\n",
    "\n",
    "xgb_model.fit(X,y)\n",
    "hyperparameters_all = xgb_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17a178f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m3_env",
   "language": "python",
   "name": "m3_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
